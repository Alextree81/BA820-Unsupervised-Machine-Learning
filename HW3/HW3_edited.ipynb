{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ozalcZj6GnO"
   },
   "source": [
    "# BA 820 Homework 3 (100 Points)\n",
    "\n",
    "Group Member Names:\n",
    "\n",
    "Reminder: you should not be sharing code across groups\n",
    "\n",
    "Please submit 1) PDF answers and 2) python notebook. Grading will be based on the homework answer write up PDF. Python notebook is for reference and back up only. So please make sure that your all the outputs and answers are clearly visible in the pdf.\n",
    "\n",
    "## 1 Latent Dirichlet Allocation [60pts]\n",
    "\n",
    "In this problem, we will use Latent Dirichlet Allocation to perform topic modeling on Amazon Review datasets. In particular, we will take an in-depth look at different aspects of LDA model.\n",
    "\n",
    "## 1.1 Installation\n",
    "\n",
    "To perform LDA and visualize, please use Python 3.X. You will also need to install Numpy, Scipy, gensim, nltk, pyLDAvis library. Refer to requirements.txt for more details.\n",
    "Use the following code to install the labraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K7m0zKTQLP-a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in d:\\anacondo\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\anacondo\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\anacondo\\lib\\site-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\anacondo\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in d:\\anacondo\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anacondo\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in d:\\anacondo\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in d:\\anacondo\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in d:\\anacondo\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\anacondo\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyldavis in d:\\anacondo\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anacondo\\lib\\site-packages (from pyldavis) (1.2.0)\n",
      "Requirement already satisfied: scipy in d:\\anacondo\\lib\\site-packages (from pyldavis) (1.9.1)\n",
      "Requirement already satisfied: setuptools in d:\\anacondo\\lib\\site-packages (from pyldavis) (63.4.1)\n",
      "Requirement already satisfied: pandas>=1.3.4 in d:\\anacondo\\lib\\site-packages (from pyldavis) (1.4.4)\n",
      "Requirement already satisfied: numexpr in d:\\anacondo\\lib\\site-packages (from pyldavis) (2.8.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\anacondo\\lib\\site-packages (from pyldavis) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in d:\\anacondo\\lib\\site-packages (from pyldavis) (1.24.2)\n",
      "Requirement already satisfied: gensim in d:\\anacondo\\lib\\site-packages (from pyldavis) (4.1.2)\n",
      "Requirement already satisfied: funcy in d:\\anacondo\\lib\\site-packages (from pyldavis) (1.18)\n",
      "Requirement already satisfied: jinja2 in d:\\anacondo\\lib\\site-packages (from pyldavis) (2.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anacondo\\lib\\site-packages (from pandas>=1.3.4->pyldavis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anacondo\\lib\\site-packages (from pandas>=1.3.4->pyldavis) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anacondo\\lib\\site-packages (from scikit-learn>=1.0.0->pyldavis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\anacondo\\lib\\site-packages (from gensim->pyldavis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anacondo\\lib\\site-packages (from jinja2->pyldavis) (2.0.1)\n",
      "Requirement already satisfied: packaging in d:\\anacondo\\lib\\site-packages (from numexpr->pyldavis) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anacondo\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyldavis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anacondo\\lib\\site-packages (from packaging->numexpr->pyldavis) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in d:\\anacondo\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anacondo\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anacondo\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anacondo\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anacondo\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anacondo\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anacondo\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anacondo\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anacondo\\lib\\site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anacondo\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "# install gensim for LDA\n",
    "%pip install nltk \n",
    "# install nltk to preprocess sentences\n",
    "%pip install pyldavis\n",
    "# to visualize LDA topics\n",
    "%pip install matplotlib \n",
    "# for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFDfBgMF6Rsu"
   },
   "source": [
    "The cell below tests if the packages we need have been installed correctly, and that we are in the correct environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9iRwy_ck6SLL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\王澍\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import gzip # to unzip the data\n",
    "import re # to replace punctuations\n",
    "from nltk.corpus import stopwords # list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in d:\\anacondo\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: pandas>=1.3.4 in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (1.4.4)\n",
      "Requirement already satisfied: jinja2 in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: gensim in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: funcy in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (1.18)\n",
      "Requirement already satisfied: scipy in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (1.9.1)\n",
      "Requirement already satisfied: setuptools in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (63.4.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (1.24.2)\n",
      "Requirement already satisfied: numexpr in d:\\anacondo\\lib\\site-packages (from pyLDAvis) (2.8.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anacondo\\lib\\site-packages (from pandas>=1.3.4->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anacondo\\lib\\site-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anacondo\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\anacondo\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anacondo\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in d:\\anacondo\\lib\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anacondo\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anacondo\\lib\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLu3zAuv6m0r"
   },
   "source": [
    "## 1.2 Datasets\n",
    "\n",
    "You can download the Amazon reviews dataset of Cellphones & Accessory 5-Core Data [here](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz). Place the downloaded dataset in the same folder as this notebook. You can use the following code to read a datat from GZIp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gbSEVGKw6nV7"
   },
   "outputs": [],
   "source": [
    "# A function to read the zipped data at a specfic path\n",
    "#\n",
    "# How to use:\n",
    "# PATH = \"/path/to/file\"\n",
    "# for line in parse(PATH):\n",
    "#   do something with line\n",
    "#\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B48OODRf70mY"
   },
   "source": [
    "## 1.3 Data Cleaning\n",
    "\n",
    "Now we will preprocess the data using the following steps:\n",
    "   1. Remove stopwords\n",
    "   2. Lower-case all words\n",
    "   3. Remove words with less than 2 characters\n",
    "   4. Remove punctuation\n",
    "   5. Split each sentence into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6JVvT5kh7qO9"
   },
   "outputs": [],
   "source": [
    "# A function to clean a single line of text\n",
    "def clean_line(line):\n",
    "    \"\"\" Clean stopwords and punction for each line\n",
    "    \n",
    "    Args: \n",
    "        line (string): one line in file\n",
    "        \n",
    "    Returns:\n",
    "        list(str): a list of all words in the sentence\n",
    "    \"\"\"\n",
    "    punctuationRegex = r'\\W+|\\d+'\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    line = line.split(\" \")\n",
    "    filtered_content = []\n",
    "    \n",
    "    for word in line:\n",
    "        word = word.lower()\n",
    "        \n",
    "        if (word not in stopWords) and (len(word)) > 1:\n",
    "            filtered_content.append(re.sub(punctuationRegex,'', word))\n",
    "        #remove empty string\n",
    "        filtered_content = list(filter(None, filtered_content))\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return filtered_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYnnn1KC8jZ8"
   },
   "source": [
    "Finally, we put parse() and clean_line() function together and then extract the first 10,000 reviews into a new text file as your experiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FXjJSwnD8jvK"
   },
   "outputs": [],
   "source": [
    "def read_dataset(fname):\n",
    "    \"\"\" Read the 10000 lines in given dataset into list and clean stop words. \n",
    "        \n",
    "    Args: \n",
    "        fname (string): filename of Amazon Review Dataset\n",
    "        \n",
    "    Returns:\n",
    "        list of list of words: we view each document as a list, including a list of all words \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    exp_dataset = []\n",
    "    for review in parse(fname):\n",
    "        line = review[\"reviewText\"]\n",
    "        new_line = clean_line(line)\n",
    "        exp_dataset.append(new_line)\n",
    "        count += 1\n",
    "        if count > 10000:\n",
    "            break\n",
    "    return exp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4cRY1JaN8mIM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = read_dataset(\"reviews_Cell_Phones_and_Accessories_5.json.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FQFnMjb8l1B"
   },
   "source": [
    "## 1.4 Topic Analysis\n",
    "\n",
    "**[5pts] Q1.4.1.1** Use topic numbers 3, 6, 9, 12, 15 respectively and print out all topics with 5 words.\n",
    "\n",
    "For this We will use gensim to train an LDA model. gensim requires the following steps:\n",
    "\n",
    "Construct a gensim.corpora.dictionary from the dataset\n",
    "Construct a gensim \"corpus\" using this dictionary, by mapping each word to an index in the dictionary\n",
    "Run LDA on this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JzfOjF9I9kDD"
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(r) # create a gensim dictionary, store it in variable \"dictionary\"\n",
    "corpus = [dictionary.doc2bow(word) for word in r]# create the gensim corpus, store it in variable \"corpus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below prints the top num words in each topic for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def print_topic_words(model,num):\n",
    "    \"\"\" print top words in model topics.\n",
    "    \n",
    "    Args: \n",
    "        model: LDA model\n",
    "        \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"    \n",
    "    for topic_id, topic in model.show_topics(num_topics=-1, num_words=num, formatted=False):\n",
    "        print(f\"Topic {topic_id}: \")\n",
    "        for word, weight in topic:\n",
    "            print(f\"    {word} ({weight:.2f})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56Sv1l9S-JeI"
   },
   "source": [
    "The following function builds multiple LDA models with number of topics specified in the list `num_topics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NhGPQYTo-Jxx"
   },
   "outputs": [],
   "source": [
    "def build_num_topic_model(dictionary, corpus, num_topics):\n",
    "    \"\"\" Build lda model with given parameters, use print_topic_words to print words\n",
    "    \n",
    "    Args: \n",
    "        dictionary: dictionary built from dataset\n",
    "        corpus: corpus built from dataset\n",
    "        num_topics: list of numbers\n",
    "        \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"    \n",
    "    for num_topic in num_topics:\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=dictionary,\n",
    "                                                num_topics=num_topic,\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                per_word_topics=True)\n",
    "        # Print the top 5 words for each topic\n",
    "        print(f\"Top 5 words for {num_topic} topics:\")\n",
    "        print_topic_words(model,5)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "k8NtFThx-Od0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for 3 topics:\n",
      "Topic 0: \n",
      "    battery (0.03)\n",
      "    iphone (0.02)\n",
      "    pack (0.01)\n",
      "    juice (0.01)\n",
      "    phone (0.01)\n",
      "\n",
      "Topic 1: \n",
      "    screen (0.03)\n",
      "    phone (0.02)\n",
      "    camera (0.01)\n",
      "    n (0.01)\n",
      "    nokia (0.01)\n",
      "\n",
      "Topic 2: \n",
      "    case (0.03)\n",
      "    iphone (0.01)\n",
      "    headset (0.01)\n",
      "    use (0.01)\n",
      "    pocket (0.01)\n",
      "\n",
      "Top 5 words for 6 topics:\n",
      "Topic 0: \n",
      "    one (0.03)\n",
      "    great (0.02)\n",
      "    good (0.02)\n",
      "    would (0.01)\n",
      "    battery (0.01)\n",
      "\n",
      "Topic 1: \n",
      "    gs (0.03)\n",
      "    iphones (0.02)\n",
      "    increase (0.02)\n",
      "    addon (0.02)\n",
      "    nokia (0.02)\n",
      "\n",
      "Topic 2: \n",
      "    iphone (0.07)\n",
      "    case (0.06)\n",
      "    mophie (0.03)\n",
      "    juice (0.03)\n",
      "    fit (0.02)\n",
      "\n",
      "Topic 3: \n",
      "    home (0.12)\n",
      "    convenient (0.09)\n",
      "    button (0.05)\n",
      "    again (0.04)\n",
      "    broke (0.02)\n",
      "\n",
      "Topic 4: \n",
      "    headset (0.03)\n",
      "    bluetooth (0.02)\n",
      "    ear (0.02)\n",
      "    sound (0.02)\n",
      "    quality (0.02)\n",
      "\n",
      "Topic 5: \n",
      "    phone (0.05)\n",
      "    battery (0.04)\n",
      "    use (0.03)\n",
      "    pack (0.03)\n",
      "    need (0.02)\n",
      "\n",
      "Top 5 words for 9 topics:\n",
      "Topic 0: \n",
      "    one (0.04)\n",
      "    great (0.03)\n",
      "    it (0.02)\n",
      "    good (0.02)\n",
      "    work (0.02)\n",
      "\n",
      "Topic 1: \n",
      "    gs (0.07)\n",
      "    rather (0.06)\n",
      "    something (0.03)\n",
      "    cables (0.03)\n",
      "    quite (0.03)\n",
      "\n",
      "Topic 2: \n",
      "    iphone (0.10)\n",
      "    case (0.08)\n",
      "    mophie (0.04)\n",
      "    pocket (0.03)\n",
      "    bottom (0.02)\n",
      "\n",
      "Topic 3: \n",
      "    pack (0.38)\n",
      "    uses (0.10)\n",
      "    inside (0.02)\n",
      "    making (0.02)\n",
      "    mount (0.02)\n",
      "\n",
      "Topic 4: \n",
      "    headset (0.08)\n",
      "    bluetooth (0.07)\n",
      "    screen (0.06)\n",
      "    wife (0.03)\n",
      "    quality (0.03)\n",
      "\n",
      "Topic 5: \n",
      "    need (0.03)\n",
      "    use (0.03)\n",
      "    cable (0.02)\n",
      "    charge (0.02)\n",
      "    extra (0.02)\n",
      "\n",
      "Topic 6: \n",
      "    battery (0.12)\n",
      "    phone (0.10)\n",
      "    life (0.04)\n",
      "    doubles (0.03)\n",
      "    available (0.02)\n",
      "\n",
      "Topic 7: \n",
      "    use (0.02)\n",
      "    juice (0.02)\n",
      "    better (0.01)\n",
      "    ear (0.01)\n",
      "    using (0.01)\n",
      "\n",
      "Topic 8: \n",
      "    glad (0.06)\n",
      "    led (0.06)\n",
      "    afford (0.06)\n",
      "    pro (0.06)\n",
      "    slimmer (0.05)\n",
      "\n",
      "Top 5 words for 12 topics:\n",
      "Topic 0: \n",
      "    one (0.06)\n",
      "    great (0.06)\n",
      "    works (0.03)\n",
      "    work (0.03)\n",
      "    product (0.02)\n",
      "\n",
      "Topic 1: \n",
      "    gs (0.22)\n",
      "    something (0.11)\n",
      "    cables (0.11)\n",
      "    apply (0.03)\n",
      "    husband (0.03)\n",
      "\n",
      "Topic 2: \n",
      "    case (0.29)\n",
      "    thanks (0.04)\n",
      "    putting (0.04)\n",
      "    bulk (0.04)\n",
      "    jeans (0.04)\n",
      "\n",
      "Topic 3: \n",
      "    iphone (0.22)\n",
      "    fit (0.05)\n",
      "    bottom (0.05)\n",
      "    size (0.04)\n",
      "    theres (0.03)\n",
      "\n",
      "Topic 4: \n",
      "    juice (0.08)\n",
      "    cable (0.03)\n",
      "    charge (0.03)\n",
      "    g (0.03)\n",
      "    plug (0.03)\n",
      "\n",
      "Topic 5: \n",
      "    protective (0.08)\n",
      "    quite (0.05)\n",
      "    longer (0.04)\n",
      "    item (0.04)\n",
      "    cover (0.03)\n",
      "\n",
      "Topic 6: \n",
      "    battery (0.23)\n",
      "    mophie (0.11)\n",
      "    life (0.07)\n",
      "    doubles (0.05)\n",
      "    handy (0.03)\n",
      "\n",
      "Topic 7: \n",
      "    phone (0.06)\n",
      "    use (0.05)\n",
      "    pack (0.03)\n",
      "    little (0.02)\n",
      "    need (0.02)\n",
      "\n",
      "Topic 8: \n",
      "    good (0.03)\n",
      "    would (0.03)\n",
      "    bluetooth (0.02)\n",
      "    screen (0.02)\n",
      "    around (0.02)\n",
      "\n",
      "Topic 9: \n",
      "    otherwise (0.15)\n",
      "    started (0.04)\n",
      "    sometimes (0.04)\n",
      "    black (0.03)\n",
      "    htc (0.03)\n",
      "\n",
      "Topic 10: \n",
      "    headset (0.04)\n",
      "    ear (0.03)\n",
      "    quality (0.03)\n",
      "    sound (0.03)\n",
      "    device (0.02)\n",
      "\n",
      "Topic 11: \n",
      "    convenient (0.10)\n",
      "    excellent (0.04)\n",
      "    everything (0.04)\n",
      "    service (0.03)\n",
      "    you (0.03)\n",
      "\n",
      "Top 5 words for 15 topics:\n",
      "Topic 0: \n",
      "    try (0.11)\n",
      "    oem (0.08)\n",
      "    decided (0.05)\n",
      "    poor (0.05)\n",
      "    picture (0.03)\n",
      "\n",
      "Topic 1: \n",
      "    iphone (0.14)\n",
      "    great (0.06)\n",
      "    one (0.06)\n",
      "    need (0.05)\n",
      "    works (0.03)\n",
      "\n",
      "Topic 2: \n",
      "    good (0.07)\n",
      "    time (0.04)\n",
      "    quality (0.04)\n",
      "    well (0.04)\n",
      "    ive (0.03)\n",
      "\n",
      "Topic 3: \n",
      "    samsung (0.15)\n",
      "    keep (0.10)\n",
      "    s (0.08)\n",
      "    highly (0.05)\n",
      "    update (0.04)\n",
      "\n",
      "Topic 4: \n",
      "    uses (0.16)\n",
      "    problems (0.08)\n",
      "    devices (0.07)\n",
      "    verizon (0.07)\n",
      "    issues (0.05)\n",
      "\n",
      "Topic 5: \n",
      "    case (0.08)\n",
      "    little (0.04)\n",
      "    like (0.03)\n",
      "    would (0.03)\n",
      "    get (0.03)\n",
      "\n",
      "Topic 6: \n",
      "    battery (0.21)\n",
      "    pack (0.10)\n",
      "    juice (0.10)\n",
      "    life (0.06)\n",
      "    doubles (0.05)\n",
      "\n",
      "Topic 7: \n",
      "    probably (0.12)\n",
      "    afford (0.08)\n",
      "    hear (0.07)\n",
      "    find (0.06)\n",
      "    unit (0.06)\n",
      "\n",
      "Topic 8: \n",
      "    headset (0.05)\n",
      "    bluetooth (0.04)\n",
      "    ear (0.04)\n",
      "    sound (0.03)\n",
      "    device (0.03)\n",
      "\n",
      "Topic 9: \n",
      "    remove (0.14)\n",
      "    otherwise (0.12)\n",
      "    tried (0.08)\n",
      "    old (0.06)\n",
      "    feel (0.05)\n",
      "\n",
      "Topic 10: \n",
      "    convenient (0.18)\n",
      "    finish (0.17)\n",
      "    almost (0.07)\n",
      "    simple (0.06)\n",
      "    install (0.04)\n",
      "\n",
      "Topic 11: \n",
      "    wall (0.10)\n",
      "    shape (0.02)\n",
      "    direct (0.02)\n",
      "    rounded (0.01)\n",
      "    popping (0.01)\n",
      "\n",
      "Topic 12: \n",
      "    wife (0.07)\n",
      "    plus (0.07)\n",
      "    got (0.06)\n",
      "    want (0.05)\n",
      "    thing (0.05)\n",
      "\n",
      "Topic 13: \n",
      "    phone (0.14)\n",
      "    use (0.13)\n",
      "    using (0.04)\n",
      "    around (0.03)\n",
      "    may (0.03)\n",
      "\n",
      "Topic 14: \n",
      "    so (0.13)\n",
      "    quite (0.06)\n",
      "    hold (0.06)\n",
      "    all (0.05)\n",
      "    second (0.04)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_num_topic_model(dictionary, corpus, [3, 6, 9, 12, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8vkk6bo-UEi"
   },
   "source": [
    "**[3pts] Q1.4.1.2**  Explain what could be interpreted for each topics, and describe the similarity and difference between different topic numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRLNs647-VF7"
   },
   "source": [
    "These topics are related to customer reviews for a product,they can be interpreted as:  \n",
    "(1) Overall positive reviews, e.g. \"great\", \"good\", \"well\"  \n",
    "(2) Description of the product's performance, e.g. \"quality\", \"fit\", \"worked\"  \n",
    "(3) Reviews of personal purchasing and using experience, e.g. \"bought\", \"got\", \"used\", \"ordered\"  \n",
    "(4) Different types of phone accessories, e.g. \"battery\", \"cable\", \"headset\", \"charger\", \"screen\", \"bluetooth\"  \n",
    "(5) Some brands of phone manufacturers, e.g. \"nokia\", \"samsung\".  \n",
    "\n",
    "As topic numbers differs, the most common topics stay the same and are identified repeatedly, like the interpretion (1)(2)(3);  \n",
    "but higher-number models can capture more details, the first topic of the 3-topics model contains \"battery\", \"iphone\", \"pack\", \"juice\", \"phone\", while the 15-topics model is able to distinguish \"battery\", \"pack\", \"juice\" from \"iphone\" and \"phone\", assign them into different topics with more collrelated words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERTTf2sGDIPp"
   },
   "source": [
    "**[2pts] Q1.4.1.3**  Which topic number would you choose? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOgDUPcvDLs8"
   },
   "source": [
    "We would choose 12, because the 12-topics model balances between \"overall user experience\" and \"product accessory details\", it gives us more information than fewer-topics models, and is more generalized than the 15-topics model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJfqY1reDX5s"
   },
   "source": [
    "## 1.5 Model Evaluation\n",
    "\n",
    "**[12 pts] Q1.5.1** Now we investigate two methods to evaluate our model and choose the topic number\n",
    "\n",
    "1.Perplexity is a measurement of how well a probability distribution or probability model predicts a sample. A low perplexity indicates the probability distribution is good at predicting the sample. We can use model.log_perplexity(document) to evaluate the perplexity of our LDA model.\n",
    "\n",
    "2.Topic coherence is a one type of interpretability measurement for a topic. It measures if a set of top keywords describe a coherent and singular concept. A good topic will have high topic coherence score. We can use CoherenceModel(model=ldamodel).get_coherence() to calculate it.\n",
    "\n",
    "Plot Perplexity and topic coherence scores of our LDA model for topic number 3,6,9,12,15,20,50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni7eZRSIDsIU"
   },
   "source": [
    "The code below trains topic models with different numbers of topics and measures their coherence and perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1ue1Pf4--UjO"
   },
   "outputs": [],
   "source": [
    "# perplexity \n",
    "# run different number of topics to get perplexity and coherence value for this model\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "def get_measurement_for_model(dictionary, corpus, topic_nums):\n",
    "    \"\"\" Build lda model with given parameters \n",
    "    \n",
    "    Args: \n",
    "        dictionary: dictionary built from dataset\n",
    "        corpus: corpus built from dataset\n",
    "        topic_nums: a list contains all possible topic number\n",
    "        \n",
    "    Returns:\n",
    "        2 lists: one of perplexities, and one of coherence value\n",
    "    \"\"\"  \n",
    "    perplexity = []\n",
    "    coherence_value=[]\n",
    "    for num_topic in topic_nums:\n",
    "        lda_model =  gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topic, passes=10,random_state = 100)\n",
    "        perplexity.append(lda_model.log_perplexity(corpus))\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, corpus = corpus, dictionary=dictionary,coherence='u_mass')\n",
    "        coherence_value.append(coherence_model_lda.get_coherence())\n",
    "        #   - Compute and store coherence\n",
    "        #   - Compute and store perplexity\n",
    "        #########################\n",
    "    return perplexity,coherence_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nX_zj0RoD4j0"
   },
   "outputs": [],
   "source": [
    "perplexity, coherence = get_measurement_for_model(dictionary, corpus, [3, 6, 9, 12, 15, 20, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yk-ojlJSD85k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.908686474115575, -7.934830146974402, -8.235094819075984, -8.566418813471827, -8.83944224906722, -9.158269620559366, -11.305392894035721]\n",
      "[-1.8242849742294032, -2.075711583042866, -4.931661796046448, -5.596069906522857, -9.879550736089534, -7.519184456309688, -8.07819140833444]\n"
     ]
    }
   ],
   "source": [
    "print(perplexity)\n",
    "print(coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcYTqBizD9az"
   },
   "source": [
    "We can now plot the coherence and perplexity of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1B9scv8sD_n8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G76jh0BXECKs"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([3, 6, 9, 12, 15, 20, 50], perplexity)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUDG-rr5ELQN"
   },
   "source": [
    "**[2pts] Q1.5.2**  From the above graph what topic number would you choose and why? Is it a good idea to choose the topic number based on perplexity? why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5SLdipiENoi"
   },
   "source": [
    "Based on the above graph and perplexity, we would choose number of topics = 50, but it's not a good idea to choose the topic number based only on perplexity. Low perplexity means more distinct and easier to interpret, but can also lead to redundancies, so based on the specific goals of the analysis, it's helpful to take coherence scores into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EBhTyUQdELuW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([3, 6, 9, 12, 15, 20, 50], coherence)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnCOd2_CEY2W"
   },
   "source": [
    "**[2pts] Q1.5.3**  From the above graph what topic number would you choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm5bcHV4EcOa"
   },
   "source": [
    "Based on the above graph and coherence, we would choose number of topics = 3, because it has the highest coherent score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppxl4L4cElVA"
   },
   "source": [
    "**[4pts]Q1.5.4** Compare two methods you implemented in the previous quesions, which one do you think is better and why? In answering, please discuss the actual topics generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMiQEut8Em__"
   },
   "source": [
    "We think 12-topics would be better, because it balances between perplexity and coherence, the actual topics generated can be interpreted as: \n",
    "\n",
    "Topic 0: Overall positive comments of the function of the product  \n",
    "one (0.06)   great (0.06)   works (0.03)   work (0.03)   product (0.02)   \n",
    "\n",
    "Topic 1: Install the cables  \n",
    "gs (0.22)   something (0.11)   cables (0.11)   apply (0.03)   husband (0.03)   \n",
    "\n",
    "Topic 2: The case can be put in to jeans\n",
    "case (0.29)   thanks (0.04)   putting (0.04)   bulk (0.04)   jeans (0.04)    \n",
    "\n",
    "Topic 3: The size ofthe product matches iphone  \n",
    "iphone (0.22)   fit (0.05)   bottom (0.05)   size (0.04)   theres (0.03)    \n",
    "\n",
    "Topic 4: The charging cable and plug  \n",
    "juice (0.08)   cable (0.03)   charge (0.03)   g (0.03)   plug (0.03)   \n",
    "\n",
    "Topic 5: The product covers something and protects it  \n",
    "protective (0.08)   quite (0.05)   longer (0.04)   item (0.04)   cover (0.03)   \n",
    "\n",
    "Topic 6: Extended battery life  \n",
    "battery (0.23)   mophie (0.11)   life (0.07)   doubles (0.05)   handy (0.03)  \n",
    "\n",
    "Topic 7: The need of the product on phone  \n",
    "phone (0.06)   use (0.05)   pack (0.03)   little (0.02)   need (0.02)  \n",
    "\n",
    "Topic 8: Possitive comments on bluetooth and screen  \n",
    "good (0.03)   would (0.03)   bluetooth (0.02)   screen (0.02)   around (0.02)   \n",
    "\n",
    "Topic 9: Some altinative probabilities  \n",
    "otherwise (0.15)   started (0.04)   sometimes (0.04)   black (0.03)   htc (0.03)   \n",
    "\n",
    "Topic 10: About audio device\n",
    "headset (0.04)   ear (0.03)   quality (0.03)   sound (0.03)   device (0.02)  \n",
    "\n",
    "Topic 11: Possitive comments about the services  \n",
    "convenient (0.10)   excellent (0.04)   everything (0.04)   service (0.03)   you (0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBkDhQzGFPyp"
   },
   "source": [
    "## 1.6 Alpha and Beta in LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jelhz4KFFgde"
   },
   "source": [
    "**[7pts]Q1.6.1** In this problem, we will check the two most important parameters in LDA model: alpha and beta. Alpha represents document-topic density - with a higher alpha, documents are made up of more topics, and with lower alpha, documents contain fewer topics. Beta represents topic-word density - with a high beta, topics are made up of most of the words in the corpus, and with a low beta they consist of few words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "x7Wr3DphEb2O"
   },
   "outputs": [],
   "source": [
    "best_topic_num = 12 # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for 12 topics:\n",
      "Topic 0: \n",
      "    one (0.04)\n",
      "    great (0.03)\n",
      "    good (0.02)\n",
      "    works (0.02)\n",
      "    product (0.02)\n",
      "\n",
      "Topic 1: \n",
      "    gs (0.19)\n",
      "    regularly (0.15)\n",
      "    something (0.09)\n",
      "    cables (0.09)\n",
      "    apply (0.02)\n",
      "\n",
      "Topic 2: \n",
      "    case (0.26)\n",
      "    away (0.05)\n",
      "    thanks (0.04)\n",
      "    bulk (0.04)\n",
      "    putting (0.04)\n",
      "\n",
      "Topic 3: \n",
      "    theres (0.05)\n",
      "    uses (0.05)\n",
      "    small (0.04)\n",
      "    bit (0.03)\n",
      "    keep (0.03)\n",
      "\n",
      "Topic 4: \n",
      "    cable (0.03)\n",
      "    usb (0.03)\n",
      "    plug (0.03)\n",
      "    port (0.03)\n",
      "    charge (0.03)\n",
      "\n",
      "Topic 5: \n",
      "    iphones (0.06)\n",
      "    protective (0.05)\n",
      "    matte (0.05)\n",
      "    quite (0.03)\n",
      "    longer (0.02)\n",
      "\n",
      "Topic 6: \n",
      "    battery (0.21)\n",
      "    mophie (0.10)\n",
      "    life (0.06)\n",
      "    doubles (0.05)\n",
      "    handy (0.03)\n",
      "\n",
      "Topic 7: \n",
      "    phone (0.04)\n",
      "    use (0.04)\n",
      "    pack (0.03)\n",
      "    juice (0.03)\n",
      "    need (0.02)\n",
      "\n",
      "Topic 8: \n",
      "    bluetooth (0.03)\n",
      "    screen (0.03)\n",
      "    bottom (0.03)\n",
      "    fit (0.02)\n",
      "    however (0.02)\n",
      "\n",
      "Topic 9: \n",
      "    iphone (0.51)\n",
      "    package (0.06)\n",
      "    otherwise (0.06)\n",
      "    started (0.02)\n",
      "    sometimes (0.01)\n",
      "\n",
      "Topic 10: \n",
      "    headset (0.03)\n",
      "    ear (0.03)\n",
      "    sound (0.02)\n",
      "    quality (0.02)\n",
      "    device (0.01)\n",
      "\n",
      "Topic 11: \n",
      "    convenient (0.08)\n",
      "    comfortable (0.05)\n",
      "    excellent (0.04)\n",
      "    earpiece (0.03)\n",
      "    everything (0.03)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 =  gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                         id2word=dictionary,\n",
    "                                         num_topics=best_topic_num,\n",
    "                                         random_state=100,\n",
    "                                         update_every=1,\n",
    "                                         chunksize=100,\n",
    "                                         passes=10,\n",
    "                                         alpha=1/best_topic_num,\n",
    "                                         eta = 1/best_topic_num,\n",
    "                                         per_word_topics=True)\n",
    "\n",
    "print(f\"Top 5 words for {best_topic_num} topics:\")\n",
    "print_topic_words(model1, num=5)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3WDzHIzGFm7v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for 12 topics:\n",
      "Topic 0: \n",
      "    one (0.04)\n",
      "    great (0.03)\n",
      "    product (0.03)\n",
      "    price (0.03)\n",
      "    works (0.02)\n",
      "\n",
      "Topic 1: \n",
      "    gs (0.10)\n",
      "    cables (0.05)\n",
      "    mount (0.02)\n",
      "    cradle (0.01)\n",
      "    sturdy (0.01)\n",
      "\n",
      "Topic 2: \n",
      "    case (0.11)\n",
      "    pocket (0.03)\n",
      "    bottom (0.03)\n",
      "    little (0.03)\n",
      "    fit (0.02)\n",
      "\n",
      "Topic 3: \n",
      "    owners (0.04)\n",
      "    trade (0.04)\n",
      "    n (0.03)\n",
      "    nokia (0.03)\n",
      "    service (0.02)\n",
      "\n",
      "Topic 4: \n",
      "    juice (0.07)\n",
      "    use (0.03)\n",
      "    cable (0.03)\n",
      "    plug (0.03)\n",
      "    charger (0.02)\n",
      "\n",
      "Topic 5: \n",
      "    sleek (0.04)\n",
      "    rather (0.04)\n",
      "    regularly (0.04)\n",
      "    love (0.03)\n",
      "    recommend (0.03)\n",
      "\n",
      "Topic 6: \n",
      "    battery (0.19)\n",
      "    life (0.05)\n",
      "    doubles (0.04)\n",
      "    handy (0.02)\n",
      "    thanks (0.02)\n",
      "\n",
      "Topic 7: \n",
      "    phone (0.03)\n",
      "    use (0.02)\n",
      "    get (0.01)\n",
      "    one (0.01)\n",
      "    like (0.01)\n",
      "\n",
      "Topic 8: \n",
      "    headset (0.03)\n",
      "    bluetooth (0.03)\n",
      "    ear (0.03)\n",
      "    sound (0.02)\n",
      "    quality (0.02)\n",
      "\n",
      "Topic 9: \n",
      "    iphone (0.21)\n",
      "    mophie (0.09)\n",
      "    screen (0.05)\n",
      "    air (0.03)\n",
      "    otherwise (0.02)\n",
      "\n",
      "Topic 10: \n",
      "    obviously (0.06)\n",
      "    normally (0.06)\n",
      "    shed (0.05)\n",
      "    laptop (0.01)\n",
      "    loose (0.01)\n",
      "\n",
      "Topic 11: \n",
      "    pack (0.11)\n",
      "    available (0.03)\n",
      "    convenient (0.03)\n",
      "    addon (0.03)\n",
      "    theres (0.02)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                         id2word=dictionary,\n",
    "                                         num_topics=best_topic_num,\n",
    "                                         random_state=100,\n",
    "                                         update_every=1,\n",
    "                                         chunksize=100,\n",
    "                                         passes=10,\n",
    "                                         alpha=1/2,\n",
    "                                         eta = 1/5,\n",
    "                                         per_word_topics=True)\n",
    "\n",
    "print(f\"Top 5 words for {best_topic_num} topics:\")\n",
    "print_topic_words(model2, num=5)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hhM9efkXFqI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for 12 topics:\n",
      "Topic 0: \n",
      "    one (0.06)\n",
      "    great (0.06)\n",
      "    works (0.03)\n",
      "    work (0.03)\n",
      "    product (0.02)\n",
      "\n",
      "Topic 1: \n",
      "    gs (0.22)\n",
      "    something (0.11)\n",
      "    cables (0.11)\n",
      "    apply (0.03)\n",
      "    husband (0.03)\n",
      "\n",
      "Topic 2: \n",
      "    case (0.29)\n",
      "    thanks (0.04)\n",
      "    putting (0.04)\n",
      "    bulk (0.04)\n",
      "    jeans (0.04)\n",
      "\n",
      "Topic 3: \n",
      "    iphone (0.22)\n",
      "    fit (0.05)\n",
      "    bottom (0.05)\n",
      "    size (0.04)\n",
      "    theres (0.03)\n",
      "\n",
      "Topic 4: \n",
      "    juice (0.08)\n",
      "    cable (0.03)\n",
      "    charge (0.03)\n",
      "    g (0.03)\n",
      "    plug (0.03)\n",
      "\n",
      "Topic 5: \n",
      "    protective (0.08)\n",
      "    quite (0.05)\n",
      "    longer (0.04)\n",
      "    item (0.04)\n",
      "    cover (0.03)\n",
      "\n",
      "Topic 6: \n",
      "    battery (0.23)\n",
      "    mophie (0.11)\n",
      "    life (0.07)\n",
      "    doubles (0.05)\n",
      "    handy (0.03)\n",
      "\n",
      "Topic 7: \n",
      "    phone (0.06)\n",
      "    use (0.05)\n",
      "    pack (0.03)\n",
      "    little (0.02)\n",
      "    need (0.02)\n",
      "\n",
      "Topic 8: \n",
      "    good (0.03)\n",
      "    would (0.03)\n",
      "    bluetooth (0.02)\n",
      "    screen (0.02)\n",
      "    around (0.02)\n",
      "\n",
      "Topic 9: \n",
      "    otherwise (0.15)\n",
      "    started (0.04)\n",
      "    sometimes (0.04)\n",
      "    black (0.03)\n",
      "    htc (0.03)\n",
      "\n",
      "Topic 10: \n",
      "    headset (0.04)\n",
      "    ear (0.03)\n",
      "    quality (0.03)\n",
      "    sound (0.03)\n",
      "    device (0.02)\n",
      "\n",
      "Topic 11: \n",
      "    convenient (0.10)\n",
      "    excellent (0.04)\n",
      "    everything (0.04)\n",
      "    service (0.03)\n",
      "    you (0.03)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                         id2word=dictionary,\n",
    "                                         num_topics=best_topic_num,\n",
    "                                         random_state=100,\n",
    "                                         update_every=1,\n",
    "                                         chunksize=100,\n",
    "                                         passes=10,\n",
    "                                         alpha='auto',\n",
    "                                         eta = 'auto',\n",
    "                                         per_word_topics=True)\n",
    "\n",
    "print(f\"Top 5 words for {best_topic_num} topics:\")\n",
    "print_topic_words(model3, num=5)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRIg6fAIFwW0"
   },
   "source": [
    "**[3pts]1.6.2**  Explain how the different alpha and beta values theoretically influence the LDA model. Then describe what you find in the empirical result (e.g difference in topic words and topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QU26drlOFxo1"
   },
   "source": [
    "Alpha value influences how many topics a document is likely to contain, Beta value inluences how many words a topic is likely to contain.\n",
    "\n",
    "The difference in alpha and beta value resulted in different topics and words generated.Take topic 0 for example.Although all 3 models has topic one related to following five words:\n",
    "    one \n",
    "    \n",
    "   great\n",
    "    \n",
    "   works \n",
    "   \n",
    "   work\n",
    "   \n",
    "   product\n",
    "    \n",
    "There weight is not exactly the same.Some of the topics in a model include general comments on products(good,lovely,recommend) while other models have fewer general comments on products. Some models have more topic words related to the product itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSsPpXqXG11h"
   },
   "source": [
    "## 1.7 LDA on a short text dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbrCxteDHM1b"
   },
   "source": [
    "**[10pts]1.7.1** In this part, we will read a dataset from twitter and build a LDA model. On Windows, download and unzip the dataset from [this link](http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip). Place the downloaded dataset in the same folder as this notebook. Use the first 10,000 lines in the \"training.1600000.processed.noemoticon.csv\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eg8B4xaRFxA3"
   },
   "outputs": [],
   "source": [
    "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip # Linux and OSX only\n",
    "!unzip trainingandtestdata.zip # Linux and OSX only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81FoZvt_HTq6"
   },
   "outputs": [],
   "source": [
    "!head -n 10000 training.1600000.processed.noemoticon.csv > twitter.csv # Linux and OSX only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read the top n rows of csv file as a dataframe\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", nrows=10000)\n",
    "\n",
    "df.to_csv('twitter.csv', index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuationRegex = r'\\W+|\\d+'\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_twitter(fname):\n",
    "    \"\"\" Read the given dataset into list and clean stop words. \n",
    "    \n",
    "    Args: \n",
    "        fname (string): filename of Twitter Dataset\n",
    "        \n",
    "    Returns:\n",
    "        list of list of words: we view each document as a list, including a list of all words \n",
    "    \"\"\"\n",
    "    twitter = []\n",
    "    \n",
    "    with open(fname,encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            tweet = line.split(\",\")[5]\n",
    "            sep = tweet.split(\" \")\n",
    "            content = []\n",
    "            for word in sep:\n",
    "                word = word.lower()\n",
    "        \n",
    "                if (word not in stopWords) and (len(word)) > 1:\n",
    "                    content.append(re.sub(punctuationRegex,'', word))\n",
    "                content = list(filter(None, content))\n",
    "            twitter.append(content)\n",
    "            \n",
    "    return twitter\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1657cE1hHY8_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twitter = read_twitter('twitter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YzcgFZx_HZgK"
   },
   "outputs": [],
   "source": [
    "twitter_dictionary = corpora.Dictionary(twitter)\n",
    "twitter_corpus = [twitter_dictionary.doc2bow(word) for word in twitter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3WoNVLuJHcyu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for 10 topics:\n",
      "Topic 0: \n",
      "    go (0.12)\n",
      "    amp (0.10)\n",
      "    theres (0.09)\n",
      "    area (0.08)\n",
      "    still (0.03)\n",
      "\n",
      "Topic 1: \n",
      "    think (0.13)\n",
      "    problem (0.11)\n",
      "    online (0.11)\n",
      "    going (0.04)\n",
      "    need (0.02)\n",
      "\n",
      "Topic 2: \n",
      "    work (0.10)\n",
      "    lol (0.04)\n",
      "    tomorrow (0.04)\n",
      "    morning (0.03)\n",
      "    new (0.02)\n",
      "\n",
      "Topic 3: \n",
      "    get (0.07)\n",
      "    cant (0.06)\n",
      "    good (0.04)\n",
      "    well (0.03)\n",
      "    much (0.02)\n",
      "\n",
      "Topic 4: \n",
      "    back (0.06)\n",
      "    bed (0.05)\n",
      "    sick (0.05)\n",
      "    hope (0.04)\n",
      "    hate (0.03)\n",
      "\n",
      "Topic 5: \n",
      "    im (0.10)\n",
      "    got (0.05)\n",
      "    like (0.03)\n",
      "    sorry (0.03)\n",
      "    know (0.03)\n",
      "\n",
      "Topic 6: \n",
      "    yesterday (0.14)\n",
      "    day (0.06)\n",
      "    really (0.04)\n",
      "    im (0.03)\n",
      "    last (0.03)\n",
      "\n",
      "Topic 7: \n",
      "    sad (0.05)\n",
      "    wish (0.04)\n",
      "    i (0.03)\n",
      "    could (0.02)\n",
      "    something (0.02)\n",
      "\n",
      "Topic 8: \n",
      "    today (0.17)\n",
      "    connection (0.12)\n",
      "    feel (0.03)\n",
      "    bad (0.02)\n",
      "    getting (0.02)\n",
      "\n",
      "Topic 9: \n",
      "    anything (0.13)\n",
      "    slow (0.13)\n",
      "    night (0.04)\n",
      "    time (0.03)\n",
      "    im (0.02)\n",
      "\n",
      "\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_topic_num=10\n",
    "twitter_model = gensim.models.ldamodel.LdaModel(corpus=twitter_corpus,\n",
    "                                         id2word=twitter_dictionary,\n",
    "                                         num_topics=best_topic_num,\n",
    "                                         random_state=100,\n",
    "                                         update_every=1,\n",
    "                                         chunksize=100,\n",
    "                                         passes=10,\n",
    "                                         per_word_topics=True)\n",
    "\n",
    "print(f\"Top 5 words for {best_topic_num} topics:\")\n",
    "print_topic_words(twitter_model, num=5)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzced6IXOU1Z"
   },
   "source": [
    "## 1.8 LDA visualization\n",
    "\n",
    "**[10pts]1.8.1** We will now visualize the LDA output using pyLDAvis. PyLDAVis shows the following:\n",
    "\n",
    "   1. The distances between topics, as a map in 2-D space.\n",
    "   2. The variance in the topic-word distribution, as the size of a circle in this map.\n",
    "   3. The most \"salient\" terms in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "iaSJ2dyHOVlM"
   },
   "outputs": [],
   "source": [
    "sentences = read_dataset(\"reviews_Cell_Phones_and_Accessories_5.json.gz\")[:1000] # CHANGE TO YOUR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "5Dn0msKKPJXF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_pt = corpora.Dictionary(sentences)\n",
    "\n",
    "# Create a bag of words representation of the dataset\n",
    "corpus_pt = [dictionary_pt.doc2bow(document) for document in sentences]\n",
    "\n",
    "# Train an LDA model on the corpus\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus_pt, num_topics=5, id2word=dictionary_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yujia\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus_pt,dictionary = dictionary_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "D_BnRDcsPNyX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el214562730108252048321655750\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el214562730108252048321655750_data = {\"mdsDat\": {\"x\": [0.008975908030497064, 0.015657830488578564, -0.0095157296668851, 0.014995274151117633, -0.03011328300330813], \"y\": [-0.01619886491749338, 0.018735078088261345, -0.01878500398683225, 0.0036046433677889493, 0.012644147448275304], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [31.403908138659602, 23.998881778610368, 20.12335609216199, 15.245552507166199, 9.228301483401836]}, \"tinfo\": {\"Term\": [\"keyboard\", \"\", \"battery\", \"one\", \"power\", \"usb\", \"motorola\", \"great\", \"like\", \"it\", \"charging\", \"work\", \"phone\", \"quality\", \"also\", \"would\", \"use\", \"phones\", \"cord\", \"fit\", \"unit\", \"well\", \"still\", \"plug\", \"time\", \"v\", \"bluetooth\", \"much\", \"inverter\", \"far\", \"liion\", \"obsessed\", \"whos\", \"workand\", \"spen\", \"thank\", \"timely\", \"antennaes\", \"lightly\", \"rubberized\", \"wouldve\", \"popping\", \"compliments\", \"recomend\", \"phoenix\", \"awhile\", \"tip\", \"acting\", \"wristlet\", \"consistently\", \"defective\", \"exposed\", \"iphones\", \"steering\", \"tension\", \"moneys\", \"junkthis\", \"pricethe\", \"duck\", \"didi\", \"jammed\", \"antennae\", \"item\", \"hence\", \"earlier\", \"sale\", \"bars\", \"house\", \"wall\", \"product\", \"phone\", \"magnetic\", \"good\", \"like\", \"wait\", \"ear\", \"i\", \"find\", \"easy\", \"pretty\", \"headset\", \"needed\", \"buttons\", \"received\", \"use\", \"little\", \"bluetooth\", \"car\", \"thing\", \"\", \"id\", \"case\", \"charger\", \"made\", \"cases\", \"screen\", \"treo\", \"makes\", \"it\", \"also\", \"make\", \"get\", \"even\", \"well\", \"works\", \"phones\", \"one\", \"sound\", \"would\", \"time\", \"price\", \"great\", \"battery\", \"much\", \"quality\", \"bought\", \"usa\", \"skill\", \"transmit\", \"asia\", \"carried\", \"underpowered\", \"habra\", \"supper\", \"antiglare\", \"husband\", \"regularly\", \"thumbdrive\", \"functioned\", \"hubs\", \"wasnt\", \"firmly\", \"retracted\", \"bb\", \"sizedesign\", \"softphone\", \"guessing\", \"pool\", \"crack\", \"differentso\", \"lives\", \"copmared\", \"minus\", \"engaged\", \"gerat\", \"valuables\", \"thoroughly\", \"parties\", \"usb\", \"kit\", \"landline\", \"inches\", \"hub\", \"washing\", \"cyberpower\", \"nexus\", \"europe\", \"work\", \"hard\", \"galaxy\", \"great\", \"fit\", \"still\", \"jack\", \"perfectly\", \"two\", \"unit\", \"used\", \"plugged\", \"im\", \"ive\", \"\", \"would\", \"works\", \"back\", \"give\", \"hear\", \"even\", \"quality\", \"it\", \"bit\", \"phone\", \"sound\", \"one\", \"got\", \"headset\", \"good\", \"ear\", \"bought\", \"charger\", \"get\", \"case\", \"use\", \"well\", \"like\", \"yellowed\", \"tactile\", \"mo\", \"decrease\", \"ios\", \"timefor\", \"buyi\", \"bubbles\", \"buyingbut\", \"sun\", \"iidint\", \"anti\", \"recommencement\", \"glare\", \"jewelers\", \"droppings\", \"incase\", \"grate\", \"extent\", \"tinker\", \"girlfreind\", \"repalcement\", \"cobbled\", \"jewelrywatch\", \"stained\", \"handed\", \"folded\", \"aliph\", \"munch\", \"bough\", \"tablet\", \"counterfeit\", \"sgsii\", \"wap\", \"sellers\", \"amplifier\", \"send\", \"typing\", \"task\", \"keys\", \"inconvenience\", \"iphone\", \"feels\", \"light\", \"device\", \"keyboard\", \"truly\", \"leave\", \"set\", \"driving\", \"forget\", \"replace\", \"ssh\", \"phone\", \"well\", \"one\", \"get\", \"nice\", \"type\", \"another\", \"kind\", \"might\", \"like\", \"great\", \"also\", \"\", \"use\", \"really\", \"bought\", \"using\", \"battery\", \"case\", \"product\", \"would\", \"ive\", \"time\", \"headset\", \"good\", \"cant\", \"better\", \"work\", \"works\", \"bluetooth\", \"quality\", \"used\", \"sound\", \"it\", \"jealous\", \"powers\", \"earpeice\", \"gripping\", \"simplized\", \"refurbed\", \"townonce\", \"extends\", \"peice\", \"onedifferent\", \"contour\", \"vastly\", \"truckthe\", \"six\", \"rapid\", \"inone\", \"fittting\", \"recived\", \"batters\", \"deploying\", \"giftee\", \"doubled\", \"setfills\", \"defenetly\", \"unstuck\", \"tryit\", \"alternate\", \"ajoke\", \"orginal\", \"ifi\", \"entertainment\", \"tab\", \"repairs\", \"retail\", \"este\", \"range\", \"doubles\", \"battery\", \"packaged\", \"beeping\", \"logitech\", \"eyeglasses\", \"motorola\", \"compared\", \"dying\", \"app\", \"one\", \"actually\", \"lg\", \"handsets\", \"much\", \"mm\", \"it\", \"awesome\", \"came\", \"headset\", \"complained\", \"flaws\", \"use\", \"long\", \"price\", \"life\", \"\", \"time\", \"phone\", \"works\", \"great\", \"case\", \"sound\", \"volume\", \"away\", \"get\", \"quality\", \"like\", \"ear\", \"bluetooth\", \"still\", \"also\", \"good\", \"better\", \"well\", \"bought\", \"used\", \"would\", \"im\", \"really\", \"work\", \"inverter\", \"sabrent\", \"width\", \"aa\", \"flawless\", \"vehicles\", \"subaru\", \"watts\", \"watt\", \"accomodate\", \"mercedes\", \"patient\", \"purchasers\", \"changer\", \"atomically\", \"monthsit\", \"economical\", \"worrying\", \"jobslike\", \"twocharge\", \"solvedhas\", \"shining\", \"isno\", \"watchout\", \"smells\", \"bug\", \"whoa\", \"pluged\", \"signature\", \"gshock\", \"boy\", \"inverters\", \"ac\", \"fills\", \"dc\", \"meet\", \"keyboard\", \"wedge\", \"dual\", \"charging\", \"natural\", \"mins\", \"power\", \"stowaway\", \"laptop\", \"symbols\", \"\", \"input\", \"w\", \"cord\", \"mom\", \"instruction\", \"phones\", \"plug\", \"far\", \"quality\", \"v\", \"would\", \"one\", \"phone\", \"unit\", \"like\", \"first\", \"work\", \"bluetooth\", \"it\", \"also\", \"well\", \"right\", \"even\", \"need\", \"use\", \"time\", \"battery\", \"great\", \"little\", \"fit\", \"sound\", \"good\", \"headset\", \"charger\", \"really\", \"works\"], \"Freq\": [112.0, 604.0, 222.0, 422.0, 95.0, 120.0, 98.0, 325.0, 321.0, 249.0, 57.0, 181.0, 913.0, 182.0, 155.0, 221.0, 320.0, 131.0, 78.0, 111.0, 80.0, 226.0, 106.0, 66.0, 170.0, 60.0, 177.0, 144.0, 10.0, 79.0, 2.2136008534711955, 2.2121145890660068, 2.2101206995371134, 2.158978465737985, 2.7930372134115227, 7.499978382595288, 3.8647157548544477, 1.9018149444177719, 2.588837908159454, 3.8424600425422986, 1.9234610606786853, 2.516030431216573, 3.2225655143399043, 1.9010477569330788, 2.489145309200216, 2.508765266651371, 3.7383687299013215, 1.8652357784012692, 1.8361865023958945, 1.8636994086036114, 3.6092904330158437, 1.8343266183897176, 2.4176900911398067, 1.208523643532495, 1.2085243475895322, 1.208328033019038, 1.208394566409038, 1.2082082259799019, 1.2083166507636058, 1.2081229177355808, 1.8446436355248028, 3.5682478974130345, 38.46202387316974, 2.3978448354367985, 2.9516396727738576, 3.5728022076999584, 9.125786423153546, 7.268718175753283, 7.342915930658636, 73.74140203131398, 387.7107149318901, 6.578419821332457, 137.29990885435598, 143.11937771958597, 5.949776680387821, 79.71348042240705, 29.232249164388303, 40.377866332650626, 44.23858468633445, 33.60277240236365, 128.2313988792796, 26.84953240250635, 22.990122656168708, 18.634979778853147, 120.58367224997632, 56.67326082245353, 71.41649680085735, 45.044176135541214, 49.36906521260387, 195.96384870561403, 20.836716332507525, 84.48332979190724, 58.37798004509443, 36.71395726687244, 23.287364272293825, 38.41655868594593, 21.370934159872686, 28.984959925669717, 82.94006680648548, 56.81541275445978, 34.43846745298875, 80.14742738529988, 59.67269775404354, 72.71281788236547, 71.1062986577653, 48.21906408076126, 111.29014940083326, 58.230518584286195, 61.08087941759637, 52.4509875891679, 48.20472760200172, 70.51037727167406, 57.34491621590493, 47.72157550090433, 47.604822191823565, 45.66213544563447, 4.931393999192453, 3.984896424268996, 2.798233788930549, 2.0875103240407906, 2.0873429933743797, 2.0861112388010548, 2.08626673257145, 2.0845692140745777, 2.0283202842054826, 4.519014835371971, 1.9232319626796297, 1.904568405906413, 1.8864030748473337, 4.830086669209237, 2.9643400539916698, 3.0024623917341025, 2.1736084980715247, 3.9390248652679425, 1.1384866478993259, 1.1385103216913584, 1.138620440693691, 1.1386348781198927, 1.1384719414527602, 1.1383141161725439, 1.6798322014078428, 1.1382892766256008, 1.1382067770473059, 1.1382552007128268, 1.1383659474293422, 1.1382541246313707, 2.2783696908347473, 2.1993533882129928, 66.44134385647583, 11.145865200672954, 3.2524945810600707, 4.506164988011814, 33.41434076436663, 1.6265285064838753, 4.082166296629224, 2.605052955742138, 3.1514193259775363, 74.47270506421384, 28.182137161489155, 24.832703065075854, 117.90662965592209, 44.806264185548464, 42.888523466538906, 11.02633837686404, 19.972981471261637, 44.26110123307472, 31.696992238423, 50.44450632161373, 15.216922391044044, 51.35920425473651, 49.15680699077826, 154.97155810775914, 68.79475982674724, 68.18732762735179, 40.575197986992976, 18.646498729975914, 24.838272862692214, 53.091052619606195, 55.101804080573054, 67.633389589298, 26.396011247977807, 165.57826632525823, 50.66645457840666, 90.36345531526507, 37.678696618845564, 74.8472158455155, 69.07490256868175, 47.96044258437924, 42.60752272899013, 40.50213923000557, 56.036623302148136, 50.795113746839, 56.87781482839781, 46.32651763200741, 38.737377120334415, 2.6869513408738883, 1.587070866450737, 2.164881050479485, 1.5743827691785917, 2.4060606190089233, 1.4980880105864849, 1.008343261300884, 1.0082752874714047, 1.0081003150143264, 1.008154603847163, 1.0079572992801784, 1.0081098644350608, 1.0079882785033483, 1.0079507575510138, 1.0078757156463451, 1.0079362454391891, 1.0080291079164094, 1.0079210565967613, 1.0076665306976595, 1.007783830668885, 1.0077796199006874, 1.0079018825630033, 1.007727812413396, 1.007561111108135, 1.0076148735949468, 1.0074930620863665, 1.0074502024814955, 1.0074108769142192, 1.0075579530319867, 1.007573517835861, 2.906610274682474, 3.478278000602621, 1.5221460843002723, 4.222754450285545, 4.577838005489001, 1.965036487964155, 11.258040989100767, 5.2557515338079215, 1.4349404733846665, 17.185153193604297, 1.807616467734125, 18.971943352216478, 11.327703938165852, 23.152439735945116, 37.75535015991293, 38.14590251949259, 3.735358632923736, 8.657948773073633, 24.60656717616156, 9.827836727631201, 7.766823899364494, 11.761244631815584, 1.8233885015574536, 197.45563491057962, 60.46119341464175, 100.55751413876136, 64.7933135457915, 31.495015806381662, 14.654393682107875, 22.879353372165692, 12.430215390789762, 12.847113925444999, 69.52857021804932, 69.1259774675771, 38.94979350998536, 103.92096990445368, 64.97011768703572, 34.568465138599, 37.77440448754647, 29.96326104982307, 46.01509199836154, 45.697561577792214, 33.91245151490789, 43.776931550473336, 30.9472887038195, 34.5587346548321, 51.124159015844405, 47.27114730870479, 22.054040399235554, 27.198059198913757, 31.18691269426899, 33.042008731509924, 30.040676624678696, 29.77986164250441, 27.114248068703926, 27.395322861292968, 28.35203586352831, 1.7155303721809068, 1.7140134803542908, 0.9366471499352705, 0.9365731510437739, 0.9361694326880872, 0.9362092519530264, 0.9362984038122969, 0.9361984853706609, 0.9360203525502527, 0.9360210931088282, 0.9361938711210757, 0.9360027500425757, 0.935848827790979, 0.9358999832987266, 0.9355789226732644, 0.9357060139180134, 0.9357515867534233, 0.9355544842402759, 0.9357757973222348, 0.935598405060402, 0.9355528322249922, 0.9355323244490578, 0.9354650475507841, 0.9353560715081103, 0.9355266278446316, 0.9355315838904824, 0.9354922773199414, 0.9354565026441447, 0.9352286954331399, 0.9353772059105316, 1.4136686708201582, 1.7161525553163393, 1.7133268116567533, 2.66158529342796, 1.3539733833772745, 15.0650595971738, 2.4930143374813283, 70.57967832235872, 2.908928211787938, 1.7194764100669546, 6.141143282047843, 2.5171380900413407, 30.750525900655926, 10.591284631253233, 3.100884184632588, 2.06678163391705, 87.65522183481858, 15.481686458490396, 13.461874695252657, 1.3231582853261263, 33.769336143085546, 8.035449735208703, 50.808359408161394, 7.038198518526433, 15.173090003512785, 60.831867577807685, 4.871039296656593, 1.6373386658944153, 58.063500118002615, 20.20848636388984, 30.57097622079489, 18.19591703565543, 86.22316292986132, 32.39733129771793, 111.49899494612062, 39.53097847418341, 50.115134602521834, 38.30039889748639, 32.155405166574766, 19.296231219617013, 13.7526157133167, 38.07720137878324, 30.747897259509486, 44.83644401448261, 29.748089406760727, 29.235378602179477, 20.992718298929393, 26.489057457232263, 35.39782126031281, 23.172769620208317, 28.611696120461893, 23.555823885135204, 22.530549931959435, 26.03314316596557, 22.7073561271288, 21.193940596397923, 21.598729457988465, 6.750847116256323, 3.434630282568107, 1.274133796758286, 2.508727571489625, 1.6541683454406764, 1.6270552859998453, 1.988921589726595, 2.297607825874757, 1.1295987199732314, 0.7291076891097248, 0.7289350023703459, 0.7289427263778581, 0.7287359022838497, 0.7288295558749345, 0.7285410090228733, 0.7285730774469193, 0.7286523864526244, 0.7284291488426526, 0.7283576328088125, 0.7282536345648095, 0.7284317694880585, 0.7283132887299704, 0.7282938407824844, 0.7282967372853014, 0.7282733583697066, 0.7280848787935396, 0.7280636377728811, 0.7280427415739866, 0.7280244660204981, 0.7281245332963922, 1.4305106046317053, 1.740680126079612, 4.913295798248216, 1.0832912949716405, 2.0290603602644395, 1.4040197415817193, 31.478128909603992, 1.0587448818484864, 3.2293636795029843, 13.412006367570454, 1.0257614387697132, 1.2927294827725009, 18.746578914683496, 2.433270086958931, 7.216702422762722, 1.7170155601355463, 63.12498986674062, 2.3029184948254793, 4.777588848263436, 12.655333902509142, 0.9713598056102078, 1.4500679295811834, 16.814810153042142, 10.071423876327739, 11.19475166770204, 19.306236223561957, 9.308603101286753, 21.49468147883968, 32.198001996018114, 51.179282602965905, 10.860389313367719, 24.84021616232733, 11.919016404101646, 17.046898923908042, 16.33774013934292, 19.733250254863847, 15.065535413460793, 18.40216873000551, 9.502514309879365, 15.461651207854782, 12.915271030745288, 20.374113365006508, 14.680091990589313, 16.18464589673346, 18.282555853101947, 12.688356241482888, 11.700684090614892, 13.951046093539684, 16.51185471668188, 15.79150605209094, 12.180588815071077, 11.97561682772106, 12.451485206537322], \"Total\": [112.0, 604.0, 222.0, 422.0, 95.0, 120.0, 98.0, 325.0, 321.0, 249.0, 57.0, 181.0, 913.0, 182.0, 155.0, 221.0, 320.0, 131.0, 78.0, 111.0, 80.0, 226.0, 106.0, 66.0, 170.0, 60.0, 177.0, 144.0, 10.0, 79.0, 2.8510018816025844, 2.8510549638295446, 2.8514255495754677, 2.8437089110949056, 3.784245692013794, 10.341081735939447, 5.352848709084375, 2.7276664325144897, 3.716261962461733, 5.573278744791542, 2.8031976481188745, 3.6895977397260937, 4.764747265795139, 2.8334677805448543, 3.7106028066091046, 3.78100288776639, 5.6403221884329025, 2.814953981383828, 2.779790631771187, 2.8281551176227646, 5.477651379570252, 2.7879890125935156, 3.685763120570914, 1.8451321829380753, 1.84515253417124, 1.8449612676732887, 1.8451407028769098, 1.8448894691123745, 1.8450879917795409, 1.8447961092323126, 2.821399193443688, 5.551986750149022, 63.76983828761835, 3.7280268063000706, 4.620039663639044, 5.641000120094509, 15.000956438565888, 11.8856596291911, 12.186464418944182, 149.16103859038608, 913.4228937168145, 11.047164942826571, 305.5556347087372, 321.0619852347796, 9.978532366924314, 179.09578883925366, 58.80769961593387, 86.34571605523412, 95.95651245149186, 70.5343369549292, 330.82614737053814, 55.47248807590388, 46.53929431115644, 36.740091334944616, 320.869218248419, 133.99434253199252, 177.34671494066558, 103.45436233656757, 115.69161360264188, 604.2045295144288, 42.03977201802976, 225.42706816084572, 145.30486573104608, 83.53946851295328, 48.306875322344496, 88.47795373679972, 44.642983744457034, 66.22064542609263, 249.467101922337, 155.74913314908702, 82.75656013951587, 250.2283068758621, 173.09882072464163, 226.51439377948202, 224.31809869734772, 131.8391740419032, 422.0643426856964, 182.3987472841003, 221.18039543962217, 170.21162757394185, 147.06193066456132, 325.94067485079705, 222.5422590736076, 144.73687514175748, 182.5406213979725, 157.85914847003315, 5.581822334683659, 4.634648647665869, 3.5996026996395862, 2.73621754944845, 2.7360458202556956, 2.7354761558715257, 2.735932313694354, 2.735856596011169, 2.7307500402479223, 6.31255213972162, 2.719481256140026, 2.7142436289067047, 2.7153396134286254, 7.2433193059886705, 4.511227070244043, 4.634383050798549, 3.3923290618774877, 6.165124103696236, 1.7869387930213465, 1.7870314826229883, 1.7872062881818156, 1.7872654401101493, 1.787046180701078, 1.7868421255627644, 2.636883957233116, 1.786808219303421, 1.7867739470322157, 1.7868704089754595, 1.787066714616502, 1.7869884188796232, 3.616832027536134, 3.501280956864532, 120.06309827657874, 20.14119457153379, 5.452518054643445, 7.7169173598526, 68.78554353617054, 2.630799962622316, 7.192170654483111, 4.410206473497777, 5.447258546509263, 181.21393244129862, 62.87387034155371, 54.87227156736904, 325.94067485079705, 111.78593265797122, 106.82066720342482, 22.4034379576661, 45.82603185968268, 118.8418163881492, 80.8127767295324, 142.61149565946806, 33.64608107531383, 149.1891488933895, 141.92160996871834, 604.2045295144288, 221.18039543962217, 224.31809869734772, 117.9044452930896, 44.10042068397451, 64.65409397438485, 173.09882072464163, 182.5406213979725, 249.467101922337, 72.8387057854071, 913.4228937168145, 182.3987472841003, 422.0643426856964, 121.13476969518355, 330.82614737053814, 305.5556347087372, 179.09578883925366, 157.85914847003315, 145.30486573104608, 250.2283068758621, 225.42706816084572, 320.869218248419, 226.51439377948202, 321.0619852347796, 3.358602738348469, 2.491337373718026, 3.427160006018195, 2.5729313896292676, 3.9456304753026608, 2.482402775608321, 1.6785230019902893, 1.6785385564498312, 1.6783900182857878, 1.6785082780589082, 1.6782484425241198, 1.6785391872702216, 1.6783441447437186, 1.6783006167342727, 1.6782863988241152, 1.678425522399886, 1.6785892679167258, 1.678418053584184, 1.6781204175612507, 1.6783724356813348, 1.6784045116369224, 1.6786234456387044, 1.6783581908775362, 1.678093346942574, 1.6782257267065372, 1.6781227320469168, 1.678095373041155, 1.6781088557144415, 1.678370318283897, 1.678401135523781, 4.921449727321104, 5.954873009983168, 2.5828019297898512, 7.642256397745424, 8.390550080357187, 3.414897635240424, 22.37085137004584, 10.348356601841559, 2.47600978766609, 40.30174078856167, 3.2288623854443363, 48.34626809188488, 26.953516367139187, 62.07865281020753, 110.2990066430642, 112.2054573688915, 7.609607364327327, 20.973339294429575, 72.78281518829789, 24.52565460424584, 18.645001061429372, 30.672710805148377, 3.3808243343695636, 913.4228937168145, 226.51439377948202, 422.0643426856964, 250.2283068758621, 103.98585520090282, 42.506336199090484, 74.70637460913323, 34.69115633586917, 36.72040249744191, 321.0619852347796, 325.94067485079705, 155.74913314908702, 604.2045295144288, 320.869218248419, 139.48650799509306, 157.85914847003315, 118.95571138049775, 222.5422590736076, 225.42706816084572, 149.16103859038608, 221.18039543962217, 141.92160996871834, 170.21162757394185, 330.82614737053814, 305.5556347087372, 86.52056728803822, 135.67836115904382, 181.21393244129862, 224.31809869734772, 177.34671494066558, 182.5406213979725, 142.61149565946806, 182.3987472841003, 249.467101922337, 2.3990204301400597, 2.3987264364227903, 1.618796764811302, 1.6187217410665877, 1.6183954512935395, 1.6184682587805361, 1.6186790633493462, 1.6185715653504475, 1.6182777888664301, 1.61831237129636, 1.6186822592768795, 1.6185030337898128, 1.6182874004312664, 1.618645162736202, 1.6182205670447802, 1.6185557189364137, 1.6187138211850725, 1.6184012893188577, 1.6187988896293086, 1.6184990076852663, 1.6184705929537024, 1.6185317548513594, 1.6185065816525406, 1.618390365420953, 1.6187294834552168, 1.6187552515626416, 1.618717171671569, 1.6186933115816253, 1.6183830540325583, 1.6187037405690368, 2.466511106667614, 3.007036793477666, 3.0346649368681726, 4.81119053896674, 2.3824435907901216, 32.688608440089475, 4.814497602862552, 222.5422590736076, 5.942852677220352, 3.2752123850636794, 14.39528313178059, 5.106771930591121, 98.32208043530272, 28.68473537831147, 6.6829946432961655, 4.15999293484708, 422.0643426856964, 51.94246569820021, 43.69665988996089, 2.4884379461434736, 144.73687514175748, 23.917091800366812, 249.467101922337, 20.698422222052248, 55.66607095211397, 330.82614737053814, 13.218064036546183, 3.2978980123263577, 320.869218248419, 85.79439294269048, 147.06193066456132, 75.51842400295266, 604.2045295144288, 170.21162757394185, 913.4228937168145, 224.31809869734772, 325.94067485079705, 225.42706816084572, 182.3987472841003, 90.66248988569569, 55.838264005020264, 250.2283068758621, 182.5406213979725, 321.0619852347796, 179.09578883925366, 177.34671494066558, 106.82066720342482, 155.74913314908702, 305.5556347087372, 135.67836115904382, 226.51439377948202, 157.85914847003315, 142.61149565946806, 221.18039543962217, 149.1891488933895, 139.48650799509306, 181.21393244129862, 10.239380987572517, 5.486654518402485, 2.077553063905426, 4.1554474214165085, 2.780594947794909, 2.7898153006423105, 3.506427269974159, 4.325478489729042, 2.134241062429516, 1.4459461596049663, 1.4458561036724054, 1.4458859159018724, 1.4456959953876996, 1.4459069715913127, 1.4457905874648507, 1.4459262420626697, 1.4460905448531118, 1.4457120105126275, 1.4458210748636375, 1.4456753263296704, 1.446041413811224, 1.4460029106993595, 1.4460072700030033, 1.4461442359534913, 1.446106201582986, 1.446076895807194, 1.4460952985717177, 1.4460684478510855, 1.4460351390902497, 1.446250622807991, 2.9556051203566316, 3.645063370850715, 11.104598121520675, 2.209743152177202, 4.343390012059729, 2.9447323591841688, 112.2054573688915, 2.2358875590124008, 9.360337193109897, 57.248787848047606, 2.2201520002744237, 2.9810122942456454, 95.1163678261187, 6.970635398578769, 29.818409885556616, 4.519141712924419, 604.2045295144288, 6.932313098800569, 19.239507953816663, 78.25877613070514, 2.1571970003210037, 3.7953733768694446, 131.8391740419032, 66.47404906355439, 79.30967137299143, 182.5406213979725, 60.00098338391041, 221.18039543962217, 422.0643426856964, 913.4228937168145, 80.8127767295324, 321.0619852347796, 98.22047178520862, 181.21393244129862, 177.34671494066558, 249.467101922337, 155.74913314908702, 226.51439377948202, 68.72076617309422, 173.09882072464163, 127.66258607360957, 320.869218248419, 170.21162757394185, 222.5422590736076, 325.94067485079705, 133.99434253199252, 111.78593265797122, 182.3987472841003, 305.5556347087372, 330.82614737053814, 145.30486573104608, 139.48650799509306, 224.31809869734772], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.8937, -8.8943, -8.8952, -8.9186, -8.6612, -7.6734, -8.3364, -9.0455, -8.7371, -8.3422, -9.0342, -8.7656, -8.5181, -9.0459, -8.7763, -8.7685, -8.3696, -9.0649, -9.0806, -9.0657, -8.4048, -9.0816, -8.8055, -9.4989, -9.4989, -9.499, -9.499, -9.4991, -9.4991, -9.4992, -9.076, -8.4162, -6.0386, -8.8137, -8.6059, -8.4149, -7.4772, -7.7047, -7.6945, -5.3877, -3.728, -7.8045, -4.7661, -4.7246, -7.9049, -5.3098, -6.313, -5.99, -5.8987, -6.1737, -4.8344, -6.398, -6.5532, -6.7632, -4.8959, -5.651, -5.4198, -5.8806, -5.789, -4.4103, -6.6516, -5.2517, -5.6213, -6.0851, -6.5404, -6.0398, -6.6262, -6.3215, -5.2702, -5.6485, -6.1491, -5.3044, -5.5994, -5.4018, -5.4241, -5.8125, -4.9761, -5.6239, -5.5761, -5.7284, -5.8128, -5.4325, -5.6392, -5.8229, -5.8253, -5.867, -7.8237, -8.0368, -8.3904, -8.6834, -8.6835, -8.6841, -8.684, -8.6848, -8.7121, -7.9111, -8.7653, -8.7751, -8.7847, -7.8445, -8.3327, -8.3199, -8.643, -8.0484, -9.2897, -9.2896, -9.2895, -9.2895, -9.2897, -9.2898, -8.9007, -9.2898, -9.2899, -9.2899, -9.2898, -9.2899, -8.5959, -8.6312, -5.223, -7.0083, -8.2399, -7.9139, -5.9104, -8.9329, -8.0127, -8.4619, -8.2715, -5.1089, -6.0807, -6.2072, -4.6495, -5.617, -5.6608, -7.0191, -6.425, -5.6292, -5.9631, -5.4985, -6.6969, -5.4805, -5.5243, -4.3761, -5.1882, -5.1971, -5.7162, -6.4937, -6.207, -5.4473, -5.4102, -5.2053, -6.1461, -4.3099, -5.4941, -4.9155, -5.7903, -5.1039, -5.1842, -5.549, -5.6673, -5.718, -5.3933, -5.4916, -5.3784, -5.5836, -5.7625, -8.2548, -8.7813, -8.4709, -8.7894, -8.3652, -8.839, -9.2349, -9.235, -9.2352, -9.2351, -9.2353, -9.2352, -9.2353, -9.2353, -9.2354, -9.2353, -9.2352, -9.2353, -9.2356, -9.2355, -9.2355, -9.2354, -9.2355, -9.2357, -9.2356, -9.2358, -9.2358, -9.2358, -9.2357, -9.2357, -8.1762, -7.9967, -8.8231, -7.8027, -7.722, -8.5677, -6.8221, -7.5839, -8.8821, -6.3992, -8.6512, -6.3003, -6.816, -6.1011, -5.6121, -5.6018, -7.9254, -7.0848, -6.0402, -6.958, -7.1934, -6.7784, -8.6425, -3.9577, -5.1412, -4.6325, -5.072, -5.7934, -6.5585, -6.113, -6.7231, -6.6901, -5.0015, -5.0073, -5.581, -4.5996, -5.0693, -5.7003, -5.6116, -5.8433, -5.4143, -5.4212, -5.7194, -5.4641, -5.8109, -5.7006, -5.309, -5.3873, -6.1497, -5.9401, -5.8032, -5.7454, -5.8407, -5.8494, -5.9432, -5.9329, -5.8985, -8.4259, -8.4268, -9.0311, -9.0312, -9.0316, -9.0316, -9.0315, -9.0316, -9.0318, -9.0318, -9.0316, -9.0318, -9.0319, -9.0319, -9.0322, -9.0321, -9.032, -9.0323, -9.032, -9.0322, -9.0323, -9.0323, -9.0323, -9.0325, -9.0323, -9.0323, -9.0323, -9.0324, -9.0326, -9.0324, -8.6194, -8.4256, -8.4272, -7.9867, -8.6626, -6.2533, -8.0521, -4.7089, -7.8979, -8.4236, -7.1506, -8.0425, -5.5397, -6.6056, -7.8339, -8.2396, -4.4922, -6.226, -6.3658, -8.6856, -5.4461, -6.8818, -5.0376, -7.0143, -6.2461, -4.8575, -7.3823, -8.4726, -4.9041, -5.9595, -5.5456, -6.0644, -4.5087, -5.4876, -4.2516, -5.2886, -5.0513, -5.3202, -5.4951, -6.0057, -6.3444, -5.326, -5.5398, -5.1626, -5.5729, -5.5903, -5.9215, -5.6889, -5.399, -5.8227, -5.6118, -5.8063, -5.8508, -5.7063, -5.8429, -5.9119, -5.893, -6.554, -7.2297, -8.2214, -7.5438, -7.9603, -7.9769, -7.776, -7.6318, -8.3418, -8.7796, -8.7798, -8.7798, -8.7801, -8.7799, -8.7803, -8.7803, -8.7802, -8.7805, -8.7806, -8.7807, -8.7805, -8.7806, -8.7807, -8.7807, -8.7807, -8.781, -8.781, -8.781, -8.781, -8.7809, -8.1056, -7.9093, -6.8717, -8.3836, -7.756, -8.1243, -5.0143, -8.4065, -7.2913, -5.8675, -8.4382, -8.2069, -5.5326, -7.5744, -6.4872, -7.923, -4.3185, -7.6294, -6.8997, -5.9255, -8.4927, -8.092, -5.6414, -6.1539, -6.0482, -5.5032, -6.2327, -5.3958, -4.9917, -4.5283, -6.0785, -5.2512, -5.9855, -5.6277, -5.6701, -5.4813, -5.7512, -5.5512, -6.2121, -5.7253, -5.9052, -5.4494, -5.7771, -5.6796, -5.5577, -5.9229, -6.004, -5.8281, -5.6595, -5.7042, -5.9638, -5.9807, -5.9418], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9052, 0.9045, 0.9035, 0.8828, 0.8545, 0.837, 0.8325, 0.7976, 0.7967, 0.7864, 0.7816, 0.7754, 0.7672, 0.7591, 0.759, 0.748, 0.7469, 0.7467, 0.7436, 0.7412, 0.7411, 0.7396, 0.7366, 0.7351, 0.7351, 0.735, 0.735, 0.735, 0.7349, 0.7349, 0.7333, 0.7162, 0.6526, 0.7169, 0.7102, 0.7015, 0.6612, 0.6665, 0.6516, 0.4538, 0.3013, 0.6399, 0.3583, 0.3503, 0.6412, 0.3488, 0.4592, 0.3982, 0.3839, 0.4167, 0.2105, 0.4326, 0.453, 0.4794, 0.1795, 0.2977, 0.2487, 0.3268, 0.3066, 0.0323, 0.4563, 0.1768, 0.2463, 0.3361, 0.4286, 0.324, 0.4216, 0.332, 0.057, 0.1498, 0.2815, 0.0197, 0.0932, 0.0219, 0.0093, 0.1524, -0.1748, 0.0165, -0.1285, -0.0189, 0.0428, -0.3727, -0.1978, 0.0487, -0.1858, -0.0822, 1.3033, 1.2761, 1.1753, 1.1566, 1.1565, 1.1562, 1.1561, 1.1553, 1.1298, 1.0929, 1.0807, 1.0729, 1.0629, 1.0219, 1.0072, 0.9931, 0.982, 0.9792, 0.9764, 0.9763, 0.9763, 0.9763, 0.9763, 0.9763, 0.9763, 0.9763, 0.9762, 0.9762, 0.9762, 0.9761, 0.965, 0.9622, 0.8355, 0.8355, 0.9105, 0.8892, 0.7052, 0.9463, 0.8608, 0.9007, 0.8799, 0.5379, 0.6247, 0.6343, 0.4103, 0.5129, 0.5146, 0.7182, 0.5967, 0.4395, 0.4912, 0.3879, 0.6337, 0.3608, 0.3669, 0.0665, 0.2593, 0.2364, 0.3604, 0.5664, 0.4705, 0.2453, 0.2294, 0.1219, 0.4121, -0.2806, 0.1462, -0.1142, 0.2594, -0.059, -0.0598, 0.1096, 0.1175, 0.1497, -0.0692, -0.063, -0.303, -0.1599, -0.6877, 1.3802, 1.1524, 1.1439, 1.1121, 1.1087, 1.0983, 1.0937, 1.0936, 1.0935, 1.0935, 1.0935, 1.0934, 1.0934, 1.0934, 1.0934, 1.0933, 1.0933, 1.0933, 1.0933, 1.0932, 1.0932, 1.0932, 1.0932, 1.0932, 1.0931, 1.0931, 1.0931, 1.093, 1.093, 1.093, 1.0767, 1.0656, 1.0745, 1.0101, 0.9974, 1.0507, 0.9166, 0.9258, 1.0578, 0.7509, 1.0232, 0.6679, 0.7364, 0.617, 0.5312, 0.5244, 0.8917, 0.7185, 0.5188, 0.6888, 0.7276, 0.6447, 0.9859, 0.0716, 0.2825, 0.1689, 0.2521, 0.4089, 0.5384, 0.42, 0.5769, 0.5531, 0.0734, 0.0525, 0.2173, -0.157, 0.0062, 0.2083, 0.1732, 0.2245, 0.0271, 0.0073, 0.122, -0.0166, 0.0803, 0.0089, -0.264, -0.2629, 0.2364, -0.0039, -0.1564, -0.312, -0.1723, -0.2099, -0.0568, -0.2925, -0.5713, 1.5455, 1.5448, 1.3338, 1.3337, 1.3335, 1.3335, 1.3335, 1.3334, 1.3334, 1.3334, 1.3333, 1.3332, 1.3332, 1.333, 1.333, 1.3329, 1.3328, 1.3328, 1.3328, 1.3328, 1.3328, 1.3327, 1.3327, 1.3326, 1.3326, 1.3326, 1.3326, 1.3325, 1.3325, 1.3325, 1.3243, 1.32, 1.3092, 1.2889, 1.3158, 1.1062, 1.2227, 0.7325, 1.1665, 1.2365, 1.029, 1.1734, 0.7185, 0.8845, 1.113, 1.1814, 0.3091, 0.6704, 0.7035, 1.2492, 0.4255, 0.7902, 0.2896, 0.8022, 0.581, 0.1874, 0.8826, 1.1807, 0.1714, 0.435, 0.3101, 0.4577, -0.0661, 0.2219, -0.2223, 0.1449, 0.0085, 0.1083, 0.1453, 0.3336, 0.4797, -0.0019, 0.0997, -0.0877, 0.0857, 0.0782, 0.2539, 0.1094, -0.2746, 0.1136, -0.1881, -0.0214, 0.0356, -0.2587, -0.0016, -0.0034, -0.2462, 1.9663, 1.9145, 1.894, 1.8783, 1.8635, 1.8437, 1.8159, 1.7502, 1.7466, 1.6982, 1.698, 1.698, 1.6979, 1.6978, 1.6975, 1.6975, 1.6975, 1.6974, 1.6973, 1.6972, 1.6972, 1.6971, 1.697, 1.6969, 1.6969, 1.6967, 1.6967, 1.6967, 1.6966, 1.6966, 1.6572, 1.6438, 1.5675, 1.67, 1.6218, 1.6422, 1.1119, 1.6353, 1.3187, 0.9316, 1.6108, 1.5474, 0.7588, 1.3304, 0.9642, 1.4152, 0.1241, 1.2809, 0.9899, 0.561, 1.585, 1.4207, 0.3236, 0.4958, 0.425, 0.1364, 0.5195, 0.0517, -0.1904, -0.499, 0.3759, -0.1763, 0.2738, 0.0192, -0.0017, -0.1541, 0.0471, -0.1274, 0.4044, -0.0326, 0.0919, -0.3739, -0.0677, -0.2382, -0.4979, 0.0258, 0.126, -0.1877, -0.5352, -0.6592, -0.0961, -0.0722, -0.5083]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 5, 1, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 4, 1, 3, 1, 2, 3, 4, 5, 1, 3, 1, 3, 2, 1, 2, 4, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 5, 3, 5, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 4, 2, 1, 2, 3, 4, 5, 1, 3, 2, 1, 2, 3, 1, 4, 5, 1, 3, 1, 4, 4, 4, 1, 2, 3, 4, 5, 1, 2, 4, 3, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 5, 2, 2, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 4, 3, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 5, 1, 4, 3, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 4, 5, 2, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 3, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 3, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 5, 1, 2, 3, 4, 5, 1, 5, 2, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 4, 4, 1, 3, 4, 2, 5, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 2, 1, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 3, 4, 2, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 3, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 3, 5, 5, 4, 4, 2, 2, 5, 2, 5, 1, 2, 3, 4, 5, 1, 1, 3, 3, 1, 1, 2, 3, 4, 5, 1, 2, 3, 5, 5, 3, 2, 1, 2, 3, 5, 4, 5, 3, 4, 5, 3, 3, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 2, 1, 2, 3, 4, 5, 3, 1, 5, 3, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 4, 1, 2, 3, 5, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2, 5, 5, 1, 5, 1, 5, 1, 2, 3, 4, 5, 5, 1, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 1, 3], \"Freq\": [0.3243934635139464, 0.25653564716664123, 0.1721271439053593, 0.14233590746020094, 0.1042693275580542, 0.24064797327146065, 0.721943919814382, 0.1801055723145898, 0.1801055723145898, 0.1801055723145898, 0.0900527861572949, 0.4502639307864745, 0.6915886828546928, 0.7104911885688456, 0.2310248433280632, 0.192520702773386, 0.1732686324960474, 0.288781054160079, 0.096260351386693, 0.6177822524162405, 0.5959088986359339, 0.36597314442474715, 0.11557046666044647, 0.2504026777643007, 0.1669351185095338, 0.09630872221703873, 0.6177731462299554, 0.29283454639471074, 0.5856690927894215, 0.2543290328222828, 0.1740146014047198, 0.3078719871006581, 0.20078607854390745, 0.06692869284796915, 0.7204628144857578, 0.18011570362143944, 0.7332274856483485, 0.5957561238866769, 0.7323995131456345, 0.24038502364349804, 0.24038502364349804, 0.48077004728699607, 0.7309360326276496, 0.6916631002235734, 0.23281526085465704, 0.3044507257330131, 0.12536206353712304, 0.2507241270742461, 0.08954433109794502, 0.24156430603067727, 0.19325144482454182, 0.14493858361840636, 0.33819002844294815, 0.048312861206135455, 0.7934402826579792, 0.2644800942193264, 0.2629247771187887, 0.34773922135065605, 0.1526659996173612, 0.16962888846373467, 0.06785155538549387, 0.5999617448966083, 0.1999872482988694, 0.06666241609962313, 0.06666241609962313, 0.06666241609962313, 0.6177419606638053, 0.2561311287001306, 0.14379291435796807, 0.2067023143895791, 0.31904052873174166, 0.07189645717898403, 0.1622027364218768, 0.6488109456875072, 0.1622027364218768, 0.1622027364218768, 0.3053237110852453, 0.6106474221704906, 0.3095556258286986, 0.23585190539329418, 0.19900004517559194, 0.16951855700143018, 0.08107409247894487, 0.32949514603825225, 0.35695307487477324, 0.1372896441826051, 0.12356067976434458, 0.05491585767304204, 0.40034572968410653, 0.1691601674721577, 0.1691601674721577, 0.16352149522308576, 0.09021875598515076, 0.5958051259825492, 0.29139901263772694, 0.2723947292048317, 0.24072092348333962, 0.15203426746316187, 0.05067808915438729, 0.33834019068126975, 0.33834019068126975, 0.5957563477809146, 0.6915261580483273, 0.4942060325673314, 0.12892331284365166, 0.15041053165092694, 0.10743609403637638, 0.10743609403637638, 0.5957618685083621, 0.5958090724475013, 0.2694639615018556, 0.21557116920148447, 0.16167837690111336, 0.2694639615018556, 0.07185705640049482, 0.31206452808051394, 0.20804301872034264, 0.2542748006581965, 0.1618112367824887, 0.057789727422317395, 0.43497440788046926, 0.2319863508695836, 0.21265415496378498, 0.06766268567029522, 0.04833048976449659, 0.7309819101688476, 0.3726260589968934, 0.2262372501052567, 0.2040571275459178, 0.16856893145097557, 0.02661614707120667, 0.4761227019244045, 0.2277108574421065, 0.165607896321532, 0.0621029611205745, 0.0621029611205745, 0.6916074267900073, 0.3991607556167861, 0.2821653617291074, 0.11699539388767868, 0.11699539388767868, 0.08258498392071437, 0.27948189999180323, 0.1222733312464139, 0.1572085687453893, 0.1921438062443647, 0.22707904374334012, 0.5958203710241055, 0.24403223204536517, 0.13944698974020867, 0.17430873717526083, 0.3834792217855738, 0.06972349487010433, 0.15130808826998166, 0.15130808826998166, 0.22696213240497248, 0.37827022067495414, 0.07565404413499083, 0.6296241610832556, 0.2098747203610852, 0.7071747895076989, 0.6177864706114307, 0.5596571524558162, 0.2938967504626725, 0.2811186308773389, 0.17889367419467023, 0.08944683709733511, 0.16611555460933664, 0.16792969360111115, 0.5037890808033335, 0.5595826290329492, 0.13904008233962967, 0.5561603293585187, 0.13904008233962967, 0.23023490803806002, 0.23023490803806002, 0.46046981607612003, 0.38866174357804756, 0.7773234871560951, 0.7302399738177239, 0.18255999345443097, 0.6178978949494017, 0.617856418355284, 0.22665661968200548, 0.23572288446928572, 0.34451806191664835, 0.11786144223464286, 0.08159638308552197, 0.5420653236395521, 0.5596465326700594, 0.6178439174904151, 0.20770599187866057, 0.41541198375732113, 0.16309452548954703, 0.2038681568619338, 0.4077363137238676, 0.12232089411716028, 0.08154726274477352, 0.5957964691636459, 0.21366751632325715, 0.21366751632325715, 0.10683375816162857, 0.10683375816162857, 0.32050127448488575, 0.5419795719528396, 0.14963351811199166, 0.14963351811199166, 0.14963351811199166, 0.448900554335975, 0.44668833655158424, 0.2680130019309505, 0.08933766731031685, 0.16750812620684408, 0.027918021034474015, 0.6493450745912005, 0.21644835819706681, 0.6177427715063212, 0.4585410502725698, 0.14589942508672676, 0.1667422000991163, 0.1667422000991163, 0.06252832503716861, 0.6915196310211517, 0.5596376743254545, 0.4054309738548279, 0.4054309738548279, 0.4197371152314908, 0.18357858204487548, 0.5507357461346265, 0.18357858204487548, 0.18357858204487548, 0.3466228120377868, 0.30618348396671163, 0.1386491248151147, 0.12131798421322536, 0.0866557030094467, 0.717362941878852, 0.6178287209583367, 0.5959047929666825, 0.195818417895206, 0.195818417895206, 0.587455253685618, 0.31522006795899604, 0.31522006795899604, 0.11347922446523856, 0.11347922446523856, 0.13869682990195825, 0.2968072844756289, 0.07420182111890722, 0.40811001615398973, 0.14840364223781444, 0.03710091055945361, 0.45254128246295333, 0.45254128246295333, 0.4632540191619069, 0.18530160766476275, 0.19688295814381043, 0.08106945335333371, 0.06948810287428604, 0.2157784518540586, 0.6473353555621758, 0.3461600151377015, 0.244348245979554, 0.122174122989777, 0.17308000756885075, 0.122174122989777, 0.22364173564210366, 0.4025551241557866, 0.19680472736505122, 0.07156535540547317, 0.10734803310820976, 0.617774424924532, 0.35963526467349316, 0.7192705293469863, 0.3032234460442255, 0.606446892088451, 0.5959136864716659, 0.2145347155959534, 0.16090103669696507, 0.4290694311919068, 0.1072673577979767, 0.1072673577979767, 0.7365561162622398, 0.18224140744241965, 0.4556035186060491, 0.16401726669817768, 0.1457931259539357, 0.05467242223272589, 0.5595761992660673, 0.3197080338304326, 0.22379562368130285, 0.25976277748722654, 0.1518613160694555, 0.043959854651684484, 0.6178672657715726, 0.5958039275196628, 0.2721062478290742, 0.4308348923960342, 0.1360531239145371, 0.11337760326211427, 0.045351041304845706, 0.5958408106563493, 0.4483635202165118, 0.22581812332072493, 0.15381814197208799, 0.11454542487283148, 0.055636349223946724, 0.23940277488432019, 0.3137001877794541, 0.20638170248648294, 0.15685009388972704, 0.09080794909405249, 0.5957991204065914, 0.21783105171669978, 0.3620290718671912, 0.21169496575284907, 0.15340214909626745, 0.05522477367465628, 0.6177714023542382, 0.6914430903119917, 0.5595324986335704, 0.7310122366658194, 0.5959039710881183, 0.4018585239586858, 0.2862874498136898, 0.44533603304351754, 0.11133400826087939, 0.06361943329193108, 0.07952429161491384, 0.3869101672203528, 0.22670517610567548, 0.15415951975185932, 0.1843868765659494, 0.0483637709025441, 0.24747079444557682, 0.38667311632121376, 0.10826847256993986, 0.1856030958341826, 0.07733462326424276, 0.536476829141936, 0.5889450159592361, 0.08413500227989086, 0.08413500227989086, 0.08413500227989086, 0.08413500227989086, 0.14537938476478782, 0.4797519697237998, 0.18899320019422416, 0.11630350781183026, 0.05815175390591513, 0.13805825171523428, 0.6902912585761715, 0.13805825171523428, 0.7920726655923506, 0.15841453311847012, 0.49313270523070224, 0.20405491250925611, 0.13603660833950407, 0.10202745625462806, 0.06801830416975203, 0.49952697153052233, 0.1427219918658635, 0.16650899051017412, 0.11893499322155293, 0.07136099593293176, 0.6177782721676182, 0.5958593344475146, 0.26811601444676103, 0.3418479184196203, 0.17427540939039465, 0.15416670830688758, 0.06032610325052123, 0.5957383495255432, 0.12958542295690736, 0.6479271147845368, 0.12958542295690736, 0.12958542295690736, 0.12958542295690736, 0.6194132054112836, 0.6178347697891553, 0.14425199579820194, 0.14425199579820194, 0.14425199579820194, 0.14425199579820194, 0.2885039915964039, 0.26347868857762674, 0.26347868857762674, 0.26347868857762674, 0.26347868857762674, 0.09766215371941867, 0.09766215371941867, 0.09766215371941867, 0.09766215371941867, 0.6836350760359307, 0.27434365284206613, 0.27434365284206613, 0.5486873056841323, 0.506889839917557, 0.2534449199587785, 0.1654729582187303, 0.22752531755075414, 0.39299827576948443, 0.12410471866404771, 0.08273647910936514, 0.54262846921378, 0.6915594552978443, 0.3327092003731987, 0.27258103163105435, 0.11223924831866944, 0.20443577372329075, 0.08017089165619246, 0.5958929961310273, 0.1724953409852974, 0.07840697317513518, 0.047044183905081104, 0.09408836781016221, 0.26775344507700954, 0.3452610212835123, 0.2184304420365078, 0.08455371949800303, 0.07750757620650277, 0.22318003198652284, 0.49099607037035026, 0.08927201279460914, 0.1339080191919137, 0.04463600639730457, 0.7088681405479808, 0.8336736006384222, 0.5958458584307458, 0.5959144059667265, 0.6916485154252678, 0.5419640889395688, 0.17824444968168648, 0.11585889229309622, 0.3386644543952043, 0.08021000235675892, 0.27627889700661407, 0.2729410637051685, 0.14887694383918282, 0.42181800754435134, 0.07443847191959141, 0.09925129589278855, 0.20178053254345693, 0.2594321132701589, 0.34590948436021185, 0.11530316145340395, 0.05765158072670198, 0.14894846427033667, 0.5461443689912345, 0.09929897618022446, 0.09929897618022446, 0.09929897618022446, 0.18340150183425533, 0.550204505502766, 0.18340150183425533, 0.2682906308788459, 0.13414531543942296, 0.20121797315913445, 0.13414531543942296, 0.23475430201899017, 0.2383978979126122, 0.2383978979126122, 0.42911621624270196, 0.09535915916504488, 0.04767957958252244, 0.2517354879686628, 0.1830803548863002, 0.22885044360787526, 0.29750557669023786, 0.04577008872157505, 0.3310450440414718, 0.21186882818654193, 0.1721434229015653, 0.23835243170985967, 0.03972540528497661, 0.19330316391831964, 0.22552035790470623, 0.37049773084344595, 0.12886877594554644, 0.09665158195915982, 0.8072627899494832, 0.26908759664982773, 0.7015077797408449, 0.44539685972299053, 0.12147187083354287, 0.21802643482943593, 0.14015985096178024, 0.07786658386765569, 0.42539109430228866, 0.23135305128720965, 0.16418603639737459, 0.08955601985311341, 0.09701902150753952, 0.7584709954770256, 0.2778687965621993, 0.06946719914054983, 0.13893439828109966, 0.416803194843299, 0.06946719914054983, 0.25642701399724, 0.22145969390670728, 0.18649237381617453, 0.23311546727021817, 0.10490196027159818, 0.44290442180947004, 0.11970389778634326, 0.2274374057940522, 0.15561506712224624, 0.05985194889317163, 0.6336467352689814, 0.09052096218128305, 0.1810419243625661, 0.09052096218128305, 0.41084356264543626, 0.24167268390908014, 0.1812545129318101, 0.10875270775908606, 0.060418170977270036, 0.43792989049564984, 0.166111337774212, 0.166111337774212, 0.15101030706746546, 0.07550515353373273, 0.3395894356514789, 0.3395894356514789, 0.691631758831358, 0.24509535266196977, 0.24509535266196977, 0.3540266205117341, 0.10893126784976434, 0.05446563392488217, 0.3354565165431675, 0.3354565165431675, 0.5596678872898128, 0.20905551735697714, 0.292677724299768, 0.08362220694279086, 0.33448882777116345, 0.08362220694279086, 0.29178678504766925, 0.5835735700953385, 0.46356452370886575, 0.46356452370886575, 0.5420167986838643, 0.6915982094449447, 0.2847783516788417, 0.08136524333681192, 0.21358376375913127, 0.31529031793014617, 0.11187720958811638, 0.33163628793967037, 0.22799994795852338, 0.1381817866415293, 0.23490903729059984, 0.06909089332076465, 0.5958160658027376, 0.45041961085384885, 0.30549279314702904, 0.23499445626694543, 0.20366186209801937, 0.15666297084463027, 0.10183093104900968, 0.48672776247309246, 0.2343504041537112, 0.12618867915969065, 0.09013477082835046, 0.054080862497010274, 0.6802402604113615, 0.22674675347045384, 0.22674675347045384, 0.3654343172596236, 0.16348377351088422, 0.29811746934337713, 0.10578361815410156, 0.05770015535678267, 0.7014947187526664, 0.26299307658562304, 0.21323762966401869, 0.2393000066229543, 0.20849901567148493, 0.07581782388053998, 0.6179276743703956, 0.6179006864340797, 0.33653871442350125, 0.16826935721175063, 0.5048080716352519, 0.5712195121270818, 0.6916174983115796, 0.6179408794212514, 0.30550321360722205, 0.43643316229603146, 0.13092994868880944, 0.10910829057400787, 0.021821658114801575, 0.538995981040525, 0.4247758652306019, 0.18173400419659771, 0.21567228208873343, 0.12152093051700208, 0.055833941048352306, 0.3640799508099458, 0.24271996720663055, 0.1592849784793513, 0.10618998565290086, 0.12894498257852247, 0.25573889720102155, 0.3459996844484409, 0.09026078724741937, 0.15043464541236562, 0.15043464541236562, 0.6915301979557326, 0.23776914708410452, 0.445817150782696, 0.11888457354205226, 0.0891634301565392, 0.0891634301565392, 0.5595139801608707, 0.8130967687070169, 0.28386281580220174, 0.22078219006837912, 0.1261612514676452, 0.1682150019568603, 0.19975531482377157, 0.8337757776925121, 0.48203472901043487, 0.1984848884160614, 0.1559524123269054, 0.12759742826746806, 0.056709968118874694, 0.3263931037970994, 0.23119511518961208, 0.16999640822765594, 0.21079554620229338, 0.06119870696195614, 0.5420378926446616, 0.4961081036933028, 0.16760408908557528, 0.22794156115638237, 0.0603374720708071, 0.053633308507384084, 0.6917083558302484, 0.2629551692790126, 0.3013027981322019, 0.16434698079938284, 0.1698252134926956, 0.10408642117294246, 0.21414187798264195, 0.15295848427331568, 0.12236678741865255, 0.458875452819947, 0.061183393709326274, 0.6179627303997351, 0.30827354285414243, 0.20790541262256115, 0.2509203255789531, 0.15055219534737188, 0.08602982591278394, 0.5171462375197887, 0.1905275611915011, 0.1633093381641438, 0.1088728921094292, 0.0272182230273573, 0.6178937242572722, 0.705848859031464, 0.5958253574702338, 0.6178681568667079, 0.7354343757598674, 0.6590513422757094, 0.3295256711378547, 0.5957262199560825, 0.22821589015943966, 0.16301135011388548, 0.3912272402733251, 0.16301135011388548, 0.06520454004555419, 0.20784876256735443, 0.20784876256735443, 0.6235462877020633, 0.20784876256735443, 0.5895654470775598, 0.2947827235387799, 0.3201361280604219, 0.17461970621477557, 0.2619295593221634, 0.11641313747651705, 0.1455164218456463, 0.717710378964656, 0.179427594741164, 0.1822604278519734, 0.1822604278519734, 0.1822604278519734, 0.5467812835559202, 0.7090941171497412, 0.1772735292874353, 0.1772735292874353, 0.42948552034827464, 0.259951762316061, 0.16953375803221368, 0.06781350321288547, 0.06781350321288547, 0.23836339463393796, 0.11918169731696898, 0.5959084865848449, 0.11918169731696898, 0.11918169731696898, 0.22350512804778222, 0.13410307682866934, 0.4917112817051209, 0.08940205121911289, 0.044701025609556445, 0.20609260525569392, 0.2473111263068327, 0.3434876754261565, 0.15113457718750886, 0.05495802806818504, 0.6178535270329095, 0.38717641816279913, 0.7743528363255983, 0.691561540160628, 0.6915461270388866, 0.6178959531804956, 0.6178006292062015, 0.5596162576498803, 0.8630643451288385, 0.6915121440633792, 0.5595872315199558, 0.6915431262541605, 0.31798464004613186, 0.27960718348884006, 0.14802733243526828, 0.1754398014047624, 0.07675491311458355, 0.7927603660436603, 0.2957858501649936, 0.5915717003299872, 0.5958673997701531, 0.5419665914707863, 0.17786820188847158, 0.4025438253265409, 0.1497837489587129, 0.19659117050831068, 0.07489187447935645, 0.28691788992546885, 0.14345894496273442, 0.28691788992546885, 0.28691788992546885, 0.5703811446842698, 0.5957670945516209, 0.7310324681914853, 0.22128095632408962, 0.22128095632408962, 0.22128095632408962, 0.44256191264817923, 0.6651065940855952, 0.3325532970427976, 0.6095764797404508, 0.2031921599134836, 0.2031921599134836, 0.8027816790687151, 0.40387562479815936, 0.5419606138140527, 0.676911775648399, 0.09670168223548557, 0.09670168223548557, 0.09670168223548557, 0.4235397750462447, 0.26795373523333843, 0.08643668878494788, 0.12101136429892705, 0.09508035766344268, 0.27648505443069255, 0.5529701088613851, 0.7368535302800355, 0.3055020431986094, 0.2115014145221142, 0.20562637522983326, 0.1880012573529904, 0.08812558938421425, 0.4028355147785986, 0.7472656556146559, 0.18681641390366396, 0.5958153141344045, 0.7091793458542398, 0.17729483646355995, 0.17729483646355995, 0.6177876903719353, 0.8334253111601394, 0.47039866600778907, 0.22399936476561383, 0.1343996188593683, 0.044799872953122766, 0.11199968238280691, 0.6179372092580739, 0.26282564976685835, 0.13141282488342917, 0.5256512995337167, 0.13141282488342917, 0.617758613622822, 0.2776800372372189, 0.3702400496496252, 0.17670547824186658, 0.11780365216124437, 0.05048727949767616, 0.6917182452984336, 0.21173313921590295, 0.1882072348585804, 0.35288856535983826, 0.0941036174292902, 0.16468133050125786, 0.1932674024437935, 0.09663370122189675, 0.4831685061094838, 0.09663370122189675, 0.1932674024437935, 0.7311341375457165, 0.2351113372033979, 0.39597698897414385, 0.11136852814897795, 0.13611708995986194, 0.13611708995986194, 0.617768447551518, 0.8957648058648514, 0.12493430717109953, 0.549710951552838, 0.17490803003953936, 0.06663163049125309, 0.08328953811406636, 0.3771006787766131, 0.17764246851460286, 0.20257474479735413, 0.18075900304994677, 0.062330690706878196, 0.23139789571240718, 0.35060287229152604, 0.18932555103742404, 0.16127732125410196, 0.0701205744583052, 0.28582066052504096, 0.24378821044782906, 0.25219470046327147, 0.1345038402470781, 0.08406490015442382, 0.31666147666997996, 0.1333311480715705, 0.16666393508946312, 0.21666311561630205, 0.1499975415805168, 0.5596007167337792, 0.6178548814075718, 0.7168933368239582, 0.2647180772363346, 0.2426582374666401, 0.17647871815755642, 0.20956847781209825, 0.09926927896362549, 0.20790552490228809, 0.20790552490228809, 0.2598819061278601, 0.10395276245114404, 0.2598819061278601, 0.6012908290890658, 0.10021513818151098, 0.20043027636302196, 0.10021513818151098, 0.10021513818151098, 0.5744077822209298, 0.16411650920597995, 0.16411650920597995, 0.08205825460298997, 0.13085140669907575, 0.13085140669907575, 0.523405626796303, 0.13085140669907575, 0.13085140669907575, 0.7602250374089444, 0.22166917879083908, 0.6650075363725172, 0.6914939569223996, 0.46855063263643176, 0.2311882956705311, 0.4623765913410622, 0.44724968210910543, 0.44724968210910543, 0.32227532556305233, 0.2030776024095946, 0.264883829229906, 0.1280271841277879, 0.0794651487689718, 0.6915173578032389, 0.7014035489363447, 0.48133547940295685, 0.204178561226166, 0.408357122452332, 0.1710685242705715, 0.12140346883717978, 0.09381177137418438, 0.7033068652691127, 0.3165148082669599, 0.3031409431289193, 0.14711251651844615, 0.17831820184054079, 0.053495460552162234, 0.6917006933112599, 0.2757929783006097, 0.3119625492252799, 0.1989326400856857, 0.11755110550517792, 0.09494512367725909, 0.7134709182358684, 0.719478646032298, 0.8932285934701508], \"Term\": [\"\", \"\", \"\", \"\", \"\", \"aa\", \"aa\", \"ac\", \"ac\", \"ac\", \"ac\", \"ac\", \"accomodate\", \"acting\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"ajoke\", \"aliph\", \"also\", \"also\", \"also\", \"also\", \"also\", \"alternate\", \"amplifier\", \"amplifier\", \"another\", \"another\", \"another\", \"another\", \"another\", \"antennae\", \"antennae\", \"antennaes\", \"anti\", \"antiglare\", \"app\", \"app\", \"app\", \"asia\", \"atomically\", \"away\", \"away\", \"away\", \"away\", \"away\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awhile\", \"awhile\", \"back\", \"back\", \"back\", \"back\", \"back\", \"bars\", \"bars\", \"bars\", \"bars\", \"bars\", \"batters\", \"battery\", \"battery\", \"battery\", \"battery\", \"battery\", \"bb\", \"bb\", \"bb\", \"bb\", \"beeping\", \"beeping\", \"better\", \"better\", \"better\", \"better\", \"better\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bluetooth\", \"bluetooth\", \"bluetooth\", \"bluetooth\", \"bluetooth\", \"bough\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"boy\", \"boy\", \"bubbles\", \"bug\", \"buttons\", \"buttons\", \"buttons\", \"buttons\", \"buttons\", \"buyi\", \"buyingbut\", \"came\", \"came\", \"came\", \"came\", \"came\", \"cant\", \"cant\", \"cant\", \"cant\", \"cant\", \"car\", \"car\", \"car\", \"car\", \"car\", \"carried\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cases\", \"cases\", \"cases\", \"cases\", \"cases\", \"changer\", \"charger\", \"charger\", \"charger\", \"charger\", \"charger\", \"charging\", \"charging\", \"charging\", \"charging\", \"charging\", \"cobbled\", \"compared\", \"compared\", \"compared\", \"compared\", \"compared\", \"complained\", \"complained\", \"complained\", \"complained\", \"complained\", \"compliments\", \"compliments\", \"consistently\", \"contour\", \"copmared\", \"cord\", \"cord\", \"cord\", \"cord\", \"cord\", \"counterfeit\", \"counterfeit\", \"crack\", \"cyberpower\", \"cyberpower\", \"cyberpower\", \"dc\", \"dc\", \"dc\", \"decrease\", \"decrease\", \"defective\", \"defective\", \"defenetly\", \"deploying\", \"device\", \"device\", \"device\", \"device\", \"device\", \"didi\", \"differentso\", \"doubled\", \"doubles\", \"doubles\", \"driving\", \"driving\", \"driving\", \"driving\", \"driving\", \"droppings\", \"dual\", \"dual\", \"dual\", \"dual\", \"dual\", \"duck\", \"dying\", \"dying\", \"dying\", \"dying\", \"ear\", \"ear\", \"ear\", \"ear\", \"ear\", \"earlier\", \"earlier\", \"earpeice\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"economical\", \"engaged\", \"entertainment\", \"entertainment\", \"este\", \"europe\", \"europe\", \"europe\", \"europe\", \"even\", \"even\", \"even\", \"even\", \"even\", \"exposed\", \"extends\", \"extent\", \"eyeglasses\", \"eyeglasses\", \"eyeglasses\", \"far\", \"far\", \"far\", \"far\", \"far\", \"feels\", \"feels\", \"feels\", \"feels\", \"feels\", \"fills\", \"fills\", \"find\", \"find\", \"find\", \"find\", \"find\", \"firmly\", \"firmly\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fit\", \"fit\", \"fit\", \"fit\", \"fit\", \"fittting\", \"flawless\", \"flawless\", \"flaws\", \"flaws\", \"folded\", \"forget\", \"forget\", \"forget\", \"forget\", \"forget\", \"functioned\", \"galaxy\", \"galaxy\", \"galaxy\", \"galaxy\", \"galaxy\", \"gerat\", \"get\", \"get\", \"get\", \"get\", \"get\", \"giftee\", \"girlfreind\", \"give\", \"give\", \"give\", \"give\", \"give\", \"glare\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"got\", \"got\", \"got\", \"grate\", \"great\", \"great\", \"great\", \"great\", \"great\", \"gripping\", \"gshock\", \"guessing\", \"habra\", \"handed\", \"handsets\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"headset\", \"headset\", \"headset\", \"headset\", \"headset\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hence\", \"house\", \"house\", \"house\", \"house\", \"house\", \"hub\", \"hub\", \"hub\", \"hub\", \"hub\", \"hubs\", \"hubs\", \"hubs\", \"husband\", \"husband\", \"i\", \"i\", \"i\", \"i\", \"i\", \"id\", \"id\", \"id\", \"id\", \"id\", \"ifi\", \"iidint\", \"im\", \"im\", \"im\", \"im\", \"im\", \"incase\", \"inches\", \"inches\", \"inches\", \"inches\", \"inches\", \"inconvenience\", \"inone\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"inverter\", \"inverter\", \"inverter\", \"inverter\", \"inverter\", \"inverters\", \"inverters\", \"inverters\", \"ios\", \"ios\", \"iphone\", \"iphone\", \"iphone\", \"iphone\", \"iphone\", \"iphones\", \"isno\", \"it\", \"it\", \"it\", \"it\", \"it\", \"item\", \"item\", \"item\", \"item\", \"item\", \"ive\", \"ive\", \"ive\", \"ive\", \"ive\", \"jack\", \"jack\", \"jack\", \"jack\", \"jack\", \"jammed\", \"jealous\", \"jewelers\", \"jewelrywatch\", \"jobslike\", \"junkthis\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keys\", \"keys\", \"keys\", \"keys\", \"keys\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kit\", \"kit\", \"kit\", \"kit\", \"kit\", \"landline\", \"landline\", \"landline\", \"laptop\", \"laptop\", \"laptop\", \"laptop\", \"laptop\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"lg\", \"lg\", \"lg\", \"lg\", \"lg\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"light\", \"light\", \"lightly\", \"lightly\", \"liion\", \"like\", \"like\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lives\", \"logitech\", \"logitech\", \"logitech\", \"logitech\", \"logitech\", \"long\", \"long\", \"long\", \"long\", \"long\", \"made\", \"made\", \"made\", \"made\", \"made\", \"magnetic\", \"magnetic\", \"magnetic\", \"magnetic\", \"make\", \"make\", \"make\", \"make\", \"make\", \"makes\", \"makes\", \"makes\", \"makes\", \"makes\", \"meet\", \"meet\", \"mercedes\", \"might\", \"might\", \"might\", \"might\", \"might\", \"mins\", \"mins\", \"minus\", \"mm\", \"mm\", \"mm\", \"mm\", \"mm\", \"mo\", \"mo\", \"mom\", \"mom\", \"moneys\", \"monthsit\", \"motorola\", \"motorola\", \"motorola\", \"motorola\", \"motorola\", \"much\", \"much\", \"much\", \"much\", \"much\", \"munch\", \"natural\", \"need\", \"need\", \"need\", \"need\", \"need\", \"needed\", \"needed\", \"needed\", \"needed\", \"needed\", \"nexus\", \"nexus\", \"nexus\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"obsessed\", \"one\", \"one\", \"one\", \"one\", \"one\", \"onedifferent\", \"orginal\", \"packaged\", \"packaged\", \"packaged\", \"parties\", \"patient\", \"peice\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"perfectly\", \"phoenix\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"phones\", \"phones\", \"phones\", \"phones\", \"phones\", \"plug\", \"plug\", \"plug\", \"plug\", \"plug\", \"pluged\", \"plugged\", \"plugged\", \"plugged\", \"plugged\", \"plugged\", \"pool\", \"popping\", \"power\", \"power\", \"power\", \"power\", \"power\", \"powers\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"price\", \"price\", \"price\", \"price\", \"pricethe\", \"product\", \"product\", \"product\", \"product\", \"product\", \"purchasers\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"range\", \"range\", \"range\", \"range\", \"range\", \"rapid\", \"really\", \"really\", \"really\", \"really\", \"really\", \"received\", \"received\", \"received\", \"received\", \"received\", \"recived\", \"recomend\", \"recommencement\", \"refurbed\", \"regularly\", \"repairs\", \"repairs\", \"repalcement\", \"replace\", \"replace\", \"replace\", \"replace\", \"replace\", \"retail\", \"retail\", \"retail\", \"retail\", \"retracted\", \"retracted\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rubberized\", \"rubberized\", \"sabrent\", \"sabrent\", \"sabrent\", \"sabrent\", \"sale\", \"sale\", \"sale\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"sellers\", \"sellers\", \"sellers\", \"sellers\", \"sellers\", \"send\", \"send\", \"send\", \"send\", \"send\", \"set\", \"set\", \"set\", \"set\", \"set\", \"setfills\", \"sgsii\", \"sgsii\", \"shining\", \"signature\", \"simplized\", \"six\", \"sizedesign\", \"skill\", \"smells\", \"softphone\", \"solvedhas\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"spen\", \"ssh\", \"ssh\", \"stained\", \"steering\", \"still\", \"still\", \"still\", \"still\", \"still\", \"stowaway\", \"stowaway\", \"stowaway\", \"stowaway\", \"subaru\", \"sun\", \"supper\", \"symbols\", \"symbols\", \"symbols\", \"symbols\", \"tab\", \"tab\", \"tablet\", \"tablet\", \"tablet\", \"tactile\", \"task\", \"tension\", \"thank\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thoroughly\", \"thoroughly\", \"thumbdrive\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timefor\", \"timely\", \"timely\", \"tinker\", \"tip\", \"tip\", \"tip\", \"townonce\", \"transmit\", \"treo\", \"treo\", \"treo\", \"treo\", \"treo\", \"truckthe\", \"truly\", \"truly\", \"truly\", \"truly\", \"tryit\", \"two\", \"two\", \"two\", \"two\", \"two\", \"twocharge\", \"type\", \"type\", \"type\", \"type\", \"type\", \"typing\", \"typing\", \"typing\", \"typing\", \"typing\", \"underpowered\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unstuck\", \"usa\", \"usb\", \"usb\", \"usb\", \"usb\", \"usb\", \"use\", \"use\", \"use\", \"use\", \"use\", \"used\", \"used\", \"used\", \"used\", \"used\", \"using\", \"using\", \"using\", \"using\", \"using\", \"v\", \"v\", \"v\", \"v\", \"v\", \"valuables\", \"vastly\", \"vehicles\", \"volume\", \"volume\", \"volume\", \"volume\", \"volume\", \"w\", \"w\", \"w\", \"w\", \"w\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"wall\", \"wall\", \"wall\", \"wall\", \"wap\", \"wap\", \"wap\", \"wap\", \"wap\", \"washing\", \"wasnt\", \"wasnt\", \"watchout\", \"watt\", \"watts\", \"watts\", \"wedge\", \"wedge\", \"well\", \"well\", \"well\", \"well\", \"well\", \"whoa\", \"whos\", \"width\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workand\", \"works\", \"works\", \"works\", \"works\", \"works\", \"worrying\", \"would\", \"would\", \"would\", \"would\", \"would\", \"wouldve\", \"wristlet\", \"yellowed\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 5, 2, 1, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el214562730108252048321655750\", ldavis_el214562730108252048321655750_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el214562730108252048321655750\", ldavis_el214562730108252048321655750_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el214562730108252048321655750\", ldavis_el214562730108252048321655750_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukn2e3iWRoIz"
   },
   "source": [
    "# 2.word2Vec [40pts]\n",
    "\n",
    "\n",
    "In this problem, we use Amazon Review Dataset to perform Word2Vec and Doc2Vec to extract insights relevant for e-commerce business. For this question, download and use the dataset [here](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz||reviews_Electronics_5.json.gz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UKcbiFCRuJr"
   },
   "source": [
    "## 2.1 Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcw3Abp6R549"
   },
   "source": [
    "The following code reads the data from a GZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "T-HJ5AnnRpFB"
   },
   "outputs": [],
   "source": [
    "# A function to read the zipped data at a specfic path\n",
    "#\n",
    "# How to use:\n",
    "# PATH = \"/path/to/file\"\n",
    "# for line in parse(PATH):\n",
    "#   do something with line\n",
    "#\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O543cF24R81Z"
   },
   "source": [
    "We will now read the data and preprocess it using the following steps:\n",
    "\n",
    "   1. Remove stopwords\n",
    "   2. Lower-case all words\n",
    "   3. Remove words with less than 2 characters\n",
    "   4. Remove punctuation\n",
    "   5. Split each sentence into a list of words\n",
    "\n",
    "   And finally extract 10000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4_GNZ3ikR_rE"
   },
   "outputs": [],
   "source": [
    "# A function to clean a single line of text\n",
    "def clean_line(line):\n",
    "    \"\"\" Clean stopwords and punction for each line\n",
    "    \n",
    "    Args: \n",
    "        line (string): one line in file\n",
    "        \n",
    "    Returns:\n",
    "        list(str): a list of all words in the sentence\n",
    "    \"\"\"\n",
    "    line = line.split(\" \")\n",
    "    filtered_content = []\n",
    "    for word in line:\n",
    "        \n",
    "        word = word.lower()\n",
    "        \n",
    "        if (word not in stopWords) and (len(word)) > 1:\n",
    "            filtered_content.append(re.sub(punctuationRegex,'', word))\n",
    "        filtered_content = list(filter(None, filtered_content))\n",
    "    return filtered_content\n",
    "\n",
    "def read_dataset(fname):\n",
    "    \"\"\" Read the 100000 lines in given dataset into list and clean stop words. \n",
    "        \n",
    "    Args: \n",
    "        fname (string): filename of Amazon Review Dataset\n",
    "        \n",
    "    Returns:\n",
    "        list of list of words: we view each document as a list, including a list of all words \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    exp_dataset = []\n",
    "    for review in parse(fname):\n",
    "        line = review[\"reviewText\"]\n",
    "        new_line = clean_line(line)\n",
    "        exp_dataset.append(new_line)\n",
    "        count += 1\n",
    "        if count > 100000:\n",
    "            break\n",
    "    return exp_dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zaf3YFgHTNr3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r2 = read_dataset(\"reviews_Electronics_5.json.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JamafEPNS3Ii"
   },
   "source": [
    "## 2.2 Build a doc2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFMVOQgrTi9s"
   },
   "source": [
    "**[3pts]2.2.1** In this question, first we will build a Word2Vec model using ginsim using size=300, min_count=40, win- dow=10, negative=10, max_vocab_size=10000. Train the model for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "5gGK2QnKTfdO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139070585, 169477560)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "dat = r2\n",
    "model = Word2Vec(dat, vector_size=300, window=10, min_count=40, negative=10, max_vocab_size=10000, workers=4)\n",
    "\n",
    "model.train(dat, total_examples=len(r2), epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPnJE0pQT6jr"
   },
   "source": [
    "**[2pts]2.2.2** Use model.wv.doesnt_match to find a word in [\"Canon\",\"Nikon\",\"junk\"] that does not belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "pGQT-f_OTqnX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd word is: junk\n"
     ]
    }
   ],
   "source": [
    "word_list = [\"Canon\", \"Nikon\", \"junk\"]\n",
    "odd_word = model.wv.doesnt_match(word_list)\n",
    "print(\"The odd word is:\", odd_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a44R5v_-UFXp"
   },
   "source": [
    "**[3pts]2.2.3** Come up with 3 other word lists and apply the above function. Explain your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "GP9dTi1yUNGR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd word is: camera\n"
     ]
    }
   ],
   "source": [
    "word_list2 = [\"camera\", \"perfect\", \"wonderful\"]\n",
    "odd_word2 = model.wv.doesnt_match(word_list2)\n",
    "print(\"The odd word is:\", odd_word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlZKiD_DUN00"
   },
   "source": [
    "\"Canon\" and \"Nikon\" are camera brands, and \"junk\" does not belong,  \"perfect\" and \"wonderful\" are adjectives while \"camera\" is a noun. The doc2vec model is able to capture the similarity and dissimilarity between words, and find the word that doesn't belong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLz_WXiHUG4L"
   },
   "source": [
    "**[2pts]2.2.4** What are some tasks in e-commerce that can be solved with this simple function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjaKCXMEUYyM"
   },
   "source": [
    "With this function, it is easy to find similar brand name, helping companies to quickly identify their competitors.\n",
    "\n",
    "It is also easier to filter certain words/comments in review. Companies can get a brief understanding of whether the comments contains many negative/positive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZmhD59iUtR3"
   },
   "source": [
    "## 2.3 Build a doc2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRC20sS1VYJN"
   },
   "source": [
    "**[15 pts] 2.3.1**  Each review is marked by other customers as “helpful” or not. The \"helpful: [a, b]\" item in each review is (a) the number of people who marked the review as helpful, and (b) the total number of people who have marked the review as helpful or unhelpful. The \"helpfulness\" score of a review can be calculated as a/b. Define a \"helpful\" review as one with helpfulness score >= 0.8. Given a review that is only slightly helpful, could we find textually similar reviews but have higher helpfulness? Build Doc2Vec model with gensim on review data. Use product ID “B00006I5WJ” and ReviewerID with “A14453U0KFWF31” as an example, find top 5 helpful reviews of the same product with similarity score above 0.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xGDDL9a4UBGi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def read_reviewers_data(fname, min_count=0):\n",
    "    '''\n",
    "    Save all reviews into their own product asin files.\n",
    "    Make sure you have 'product' folder when you run this answer.\n",
    "    In each file, you can choose your own log structure. In this answer, log \n",
    "    strucutre is like \n",
    "        \"reviewText\"\\t\"reviewerID\"\\t\"helpful\"\n",
    "    Args: \n",
    "        fname: dataset file path\n",
    "        min_count: minimum number of reviews of a product\n",
    "    Returns:\n",
    "        none\n",
    "    '''\n",
    "    if not os.path.isdir('product'):\n",
    "        os.makedirs('product')\n",
    "    asin_list = []\n",
    "    tmp_list = []\n",
    "    last_asin = \"\"\n",
    "    j = 0\n",
    "    for i in parse(fname):\n",
    "        if last_asin != i['asin']:\n",
    "            if len(tmp_list) > min_count:\n",
    "                f = open(\"product/\" + last_asin+\".txt\", 'w')\n",
    "                for one in tmp_list:\n",
    "                    f.write(one)\n",
    "                f.close()\n",
    "            tmp_list = []\n",
    "            last_asin = i['asin']\n",
    "        tmp_list.append(i[\"reviewText\"] + '\\t' + i[\"reviewerID\"] +\n",
    "                    '\\t' + handle_helpful(i[\"helpful\"]) + \"\\n\")\n",
    "        j += 1\n",
    "        if j > 100000:\n",
    "            break\n",
    "            \n",
    "def handle_helpful(helpful):\n",
    "    '''\n",
    "    Helper function for helpful_score calculate\n",
    "    Args: \n",
    "        helpful: list. The first element is the number of people think this is helpful. The second element\n",
    "            is the total number of people evaluate this comment\n",
    "    Returns:\n",
    "        String: number represent helpfulness\n",
    "    '''\n",
    "    if helpful[1] != 0:\n",
    "        helpfulness = 1.0 * helpful[0] / helpful[1]\n",
    "        return str(helpfulness)\n",
    "    else:\n",
    "        return str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ZcaWNGSyban3"
   },
   "outputs": [],
   "source": [
    "read_reviewers_data(\"reviews_Electronics_5.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "phyr9d9Zbvbe"
   },
   "outputs": [],
   "source": [
    "class TaggedReviewDocument(object):\n",
    "    '''\n",
    "    This class could save all products and review information in its dictionary and generate iter for TaggedDocument\n",
    "        which could used for Doc2Vec model\n",
    "    '''\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "        self.helpfulness = {}  # key:reviewerID value:helpfulness\n",
    "        self.product = {}      # key:asin value:reviewerID\n",
    "        self.asin = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        for filename in os.listdir(self.dirname):\n",
    "            asin_code = filename[:-4] #delete \".txt\"\n",
    "            self.product[asin_code] = []\n",
    "            self.asin.append(asin_code)\n",
    "            for line in enumerate(open(self.dirname + \"/\" + filename)):\n",
    "                line_content = line[1].split(\"\\t\")\n",
    "                self.product[asin_code].append(line_content[1])\n",
    "                self.helpfulness[line_content[1]] = float(line_content[2])\n",
    "                yield TaggedDocument(clean_line(line_content[0]), [line_content[1], line_content[2]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "59Ccalf7bwE2"
   },
   "outputs": [],
   "source": [
    "documents = TaggedReviewDocument(\"product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "crSL0O9HbyPI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "\n",
    "model_v = Doc2Vec(documents, vector_size=100, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x27ba8dbfca0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbabO2WUcZxJ"
   },
   "source": [
    "## Find similar reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "yCI8l3_9b0ru"
   },
   "outputs": [],
   "source": [
    "def find_similar_reviews(asin,reviewer_id):\n",
    "    '''\n",
    "    If one review is similar to the specefic review and it is much helpful, save it to a list\n",
    "    Args: \n",
    "        asin: product asin\n",
    "        reviewer_id: the specific review\n",
    "    Returns:\n",
    "        list of reviewer id\n",
    "        \n",
    "    '''\n",
    "    result = []\n",
    "    model_v.save('d2v.model')\n",
    "    \n",
    "    # Get the vector representation of the target review\n",
    "    target_vec = model_v.infer_vector([reviewer_id])\n",
    "    \n",
    "    # Find similar reviews to the target review\n",
    "    similar_docs = model_v.wv.most_similar([target_vec], topn=5)\n",
    "    \n",
    "    # Filter out helpful reviews with helpfulness score >= 0.8\n",
    "    helpful_docs = [(doc_id, score) for doc_id, score in similar_docs \n",
    "                    if documents.helpfulness[doc_id] >= 0.8 and doc_id != reviewer_id and doc_id.startswith(asin)]\n",
    "    \n",
    "    # Sort the remaining helpful reviews by helpfulness score and similarity score\n",
    "    helpful_docs.sort(key=lambda x: (x[1], documents.helpfulness[x[0]]), reverse=True)\n",
    "    \n",
    "    # Return the top 5 reviews with highest helpfulness score and similarity score\n",
    "    for doc_id, _ in helpful_docs[:5]:\n",
    "        result.append(doc_id)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_reviews(asin, reviewer_id):\n",
    "    \"\"\"\n",
    "    Find top 5 helpful reviews of the same product with similarity score above 0.8.\n",
    "    Args:\n",
    "        asin (str): Product asin.\n",
    "        reviewer_id (str): Reviewer ID of the example review.\n",
    "    Returns:\n",
    "        list of str: Top 5 most helpful reviewer IDs.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    example_review = documents.product[asin].index(reviewer_id)\n",
    "    example_vector = model_v[example_review]\n",
    "    for i, doc in enumerate(model_v.docvecs):\n",
    "        if i != example_review:\n",
    "            \n",
    "            similarity = model_v.similarity_unseen_docs(model_v, [doc], [example_vector])\n",
    "            if similarity > 0.8 and documents.helpfulness[documents.product[asin][i]] > 0.8:\n",
    "                result.append(documents.product[asin][i])\n",
    "                if len(result) == 5:\n",
    "                    break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_similar_reviews(\"B00006I5WJ\", \"A14453U0KFWF31\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KIVR0OodJbc"
   },
   "source": [
    "## 2.4 Build a doc2vec model using product descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aP5_XP5dO2i"
   },
   "source": [
    "**[10pts]2.4.1** Use product descriptions (located in meta data  [here](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Electronics.json.gz)) to build a Doc2Vec model. When building the doc2vec model, use vector_size=100, window=15, min_count=5, max_vocab_size=1000, and train it for 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "6j9r0LvidJ7V"
   },
   "outputs": [],
   "source": [
    "def read_product_description(fname):\n",
    "    '''\n",
    "    Load all product descriptions\n",
    "    Args: \n",
    "        fname: dataset file path\n",
    "    Returns:\n",
    "        dict: key is asin, value is description content\n",
    "    '''\n",
    "    result = {}\n",
    "    for i in parse(fname):\n",
    "        try:\n",
    "            if \"Camera & Photo\" in i[\"categories\"][0]:\n",
    "                result[i[\"asin\"]]=i[\"description\"]\n",
    "        except:\n",
    "            continue\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "XrSISgv3df6_"
   },
   "outputs": [],
   "source": [
    "class TaggedDescriptionDocument(object):\n",
    "    '''\n",
    "    This class could save all products and review information in its dictionary and generate iter for TaggedDocument\n",
    "        which could used for Doc2Vec model\n",
    "    '''\n",
    "    def __init__(self, descriptondict):\n",
    "        self.descriptondict = descriptondict\n",
    "        \n",
    "\n",
    "    def __iter__(self):\n",
    "        for asin in self.descriptondict:\n",
    "            for content in self.descriptondict[asin]:\n",
    "                yield TaggedDocument(clean_line(content), [asin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "yTRwOCtldinm"
   },
   "outputs": [],
   "source": [
    "description_dict = read_product_description(\"meta_Electronics.json.gz\")\n",
    "des_documents = TaggedDescriptionDocument(description_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d = Doc2Vec(des_documents, vector_size=100, window=15, min_count=5, max_vocab_size=1000,epoch = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvwRTr6ueRS4"
   },
   "source": [
    "**[5pts]2.4.2** Find the most similar product for Canon EOS 5D (asin:B0007Y791C) not made by Canon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrQZo-AleN-O"
   },
   "outputs": [],
   "source": [
    "def similar_product(asin):\n",
    "    result = []\n",
    "    example_review = documents.product[asin].index(reviewer_id)\n",
    "    example_vector = model_v[example_review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ild0RccPeVU3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference** \n",
    "\n",
    "This notebook refers to the course materials posted by professor:  \n",
    "\n",
    "LDA-Demo.ipynb  \n",
    "LDA-with-Gensim-Demo.ipynb  \n",
    "word2vec-Demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
